{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tJe_q0DFTJvG"
   },
   "outputs": [],
   "source": [
    "#!pip install catboost\n",
    "#!pip install spektral\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cat\n",
    "\n",
    "\n",
    "from utils.GCN_model import GCN_model\n",
    "from utils.Stacking_regressor import Stacking_regressor\n",
    "from utils.Averaging_Models import AveragingModels\n",
    "from utils.embedding_PCA import remove_embedding, pca_node_embedding, pca_author_embedding\n",
    "\n",
    "path = \"./data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v0EpP5n8SIAf"
   },
   "source": [
    "# Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "g1PdBs8ITBwT"
   },
   "outputs": [],
   "source": [
    "def generate_data(X, y, df, features, all_data, doc2vec, Bert):\n",
    "    auth_freq_abs = np.load(path+'auth_freq_abs.npy',allow_pickle='TRUE').item()\n",
    "    auth_freq_crps = np.load(path+'auth_freq_crps.npy',allow_pickle='TRUE').item()\n",
    "    if all_data == True:\n",
    "        author_Id_train = list(df.authorID)\n",
    "        loop = pd.DataFrame(G.nodes()).iterrows()\n",
    "    else:\n",
    "        loop = df.iterrows()\n",
    "    for i, row in tqdm(loop):\n",
    "        if all_data == True:\n",
    "            node = row[0]\n",
    "        else:\n",
    "            node = row['authorID']      \n",
    "        X[i, 0:f_n] = features.loc[features.index == node,:].values\n",
    "        if len(auth_freq_abs[str(int(node))]) != 0:\n",
    "            X[i, f_n:f_n+1] = np.max(auth_freq_abs[str(int(node))])\n",
    "            X[i, f_n+1:f_n+2] = np.mean(auth_freq_abs[str(int(node))])\n",
    "            X[i, f_n+2:f_n+3] = np.max(auth_freq_crps[str(int(node))])\n",
    "            X[i, f_n+3:f_n+4] = np.mean(auth_freq_crps[str(int(node))])\n",
    "        X[i, f_n+4:f_n+4+nod_em_n] = df_node_emb_pca.loc[df_node_emb_pca.index == node,:].values\n",
    "        if (doc2vec == True) & (Bert == False):\n",
    "            X[i, f_n+4+nod_em_n:f_n+4+nod_em_n+Doc2vec_n] = auth_doc2vec_pca.loc[auth_doc2vec_pca.index == node,:].values\n",
    "        elif (doc2vec == False) & (Bert == True):\n",
    "            X[i, f_n+4+nod_em_n:f_n+4+nod_em_n+Bert_n] = df_auth_emb_Bert.loc[df_auth_emb_Bert.index == node,:].values\n",
    "        elif (doc2vec == True) & (Bert == True):\n",
    "            X[i, f_n+4+nod_em_n:f_n+4+nod_em_n+Doc2vec_n] = auth_doc2vec_pca.loc[auth_doc2vec_pca.index == node,:].values\n",
    "            X[i, f_n+4+nod_em_n+Doc2vec_n:] = df_auth_emb_Bert.loc[df_auth_emb_Bert.index == node,:].values\n",
    "        if all_data == True:\n",
    "            if node in author_Id_train:\n",
    "                y[i] = np.log(df.h_index[df.authorID == node].values[0] + 1)\n",
    "            else:\n",
    "                y[i] == -100\n",
    "        else:\n",
    "            y[i] = np.log(row['h_index']+1)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SJfZsPkLR6iJ"
   },
   "outputs": [],
   "source": [
    "def base_models():\n",
    "    lgb_reg = lgb.LGBMRegressor(boosting_type='dart',  n_estimators=2500,num_leaves=27, max_depth=-1, learning_rate=0.2)\n",
    "    cat_reg = cat.CatBoostRegressor(boosting_type='Ordered',n_estimators=1500, max_depth=5, learning_rate=0.1, metric_period=100, verbose=False)\n",
    "    xg_reg = xgb.XGBRegressor(objective= \"reg:squarederror\", n_estimators = 1500, colsample_bytree = 0.7, learning_rate = 0.1,\n",
    "                            max_depth = 5, alpha = 9, random_state = 7, ree_method=\"approx\")\n",
    "    return lgb_reg, cat_reg, xg_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8i0AvV4OzGXj"
   },
   "outputs": [],
   "source": [
    "def error(model, X_train, X_test, y_train, y_test):\n",
    "    model_name = type(model).__name__\n",
    "    print(\"---Performing \"+model_name+\"---\")\n",
    "    model.fit(X_train, y_train, verbose=False)\n",
    "    return mae(np.expm1(y_test), np.round(np.expm1(model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Vhl3UacAsN44"
   },
   "outputs": [],
   "source": [
    "# Read the graph\n",
    "G = nx.read_edgelist(path + \"collaboration_network.edgelist\", delimiter=' ', nodetype=int)\n",
    "# Read training data\n",
    "df_train = pd.read_csv(path + \"train.csv\", dtype={'authorID': np.int64, 'h_index': np.float32})\n",
    "n_train = df_train.shape[0]\n",
    "# Read test data\n",
    "df_test = pd.read_csv(path + \"test.csv\", dtype={'authorID': np.int64})\n",
    "n_test = df_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qKDT56wbTA8_"
   },
   "outputs": [],
   "source": [
    "# Node Embedding with Deep Walk\n",
    "df_node_emb = pd.read_csv(path + \"node_embd_DW_Weighted_256.csv\", index_col=0)  # Weithed Node Embedding\n",
    "#df_node_emb = pd.read_csv(path+'node_embd_DW.csv', index_col=0) # Unweithed Node Embedding\n",
    "\n",
    "# Author Emebedding with Doc2Vec\n",
    "df_auth_emb_Doc2vec = pd.read_csv(path + \"author_embedding.csv\",header = None, index_col=0)\n",
    "\n",
    "# Author Emebedding with SBERT\n",
    "df_auth_emb_Bert = pd.read_csv(path + \"df_auth_emb_Bert.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PPhhU8lFTQIv"
   },
   "outputs": [],
   "source": [
    "features_df = pd.read_csv(path + \"df_features.csv\",index_col='author_id')\n",
    "features_df.drop(columns = ['auth_lang_n'], inplace = True)\n",
    "f_n = features_df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJ4_ECH6sICm"
   },
   "source": [
    "# Graph Convolutional Network (GCN):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zhs2ZFXVsQaC"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb+') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21iLuCvjsufD"
   },
   "source": [
    "## Data preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kwqObvoFsx4W",
    "outputId": "3ca9275c-4d87-440d-fd96-5fccdfc64229"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15493\n",
      "7631\n",
      "208115\n"
     ]
    }
   ],
   "source": [
    "id_train, id_valid, h_train, h_valid = train_test_split(df_train.authorID, df_train.h_index, test_size=0.33, random_state=7)\n",
    "\n",
    "#Create mask for train, validation and test\n",
    "\n",
    "train_mask = np.in1d(G.nodes(), id_train)\n",
    "print(np.sum(train_mask))\n",
    "\n",
    "valid_mask = np.in1d(G.nodes(), id_valid)\n",
    "print(np.sum(valid_mask))\n",
    "\n",
    "test_mask = np.in1d(G.nodes(), df_test.authorID)\n",
    "print(np.sum(test_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IlyPBOfRzNGs",
    "outputId": "5eb5eb8d-fffa-4e7f-8354-6d15e51d04ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28119939295253166\n",
      "0.41239559157361055\n"
     ]
    }
   ],
   "source": [
    "df_node_emb_pca = pca_node_embedding(25, df_node_emb)\n",
    "auth_doc2vec_pca  = pca_author_embedding(64, df_auth_emb_Doc2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G3xFjwSrtDXo",
    "outputId": "5aab4a59-2123-4a3d-afcf-95f57c981bd8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231239it [34:56, 110.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load X, y and Adjencency matrix A\n",
    "dim_0 = len(list(G.nodes()))\n",
    "f_n = features_df.shape[1]\n",
    "Doc2vec_n = auth_doc2vec_pca.shape[1]\n",
    "nod_em_n = df_node_emb_pca.shape[1]\n",
    "Bert_n = df_auth_emb_Bert.shape[1]\n",
    "\n",
    "## ----You can load the data in the next cell instead of running generate data function----##\n",
    "X = np.zeros((dim_0,f_n+nod_em_n+Bert_n+Doc2vec_n+4))\n",
    "y = np.zeros(dim_0)\n",
    "X, y = generate_data(X, y, df_train, features_df,  all_data=True, doc2vec = True, Bert = True) # Doc2Vec + DW + BERT for the whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "46-lRZeZqMfO"
   },
   "outputs": [],
   "source": [
    "# save_obj(X, path + \"X_final_data\")\n",
    "# save_obj(y, path + \"y_final_data\")\n",
    "X = load_obj(path + \"X_final_data\")\n",
    "y = load_obj(path + \"y_final_data\")\n",
    "A = load_obj(path + \"A_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nKeULNjWmbJu",
    "outputId": "ab7c3194-636f-4eb4-86fa-b0bfd3bfb733"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.09861229, 2.07944154, 1.09861229, ..., 0.69314718, 1.09861229,\n",
       "       1.38629436])"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[train_mask] #get only y_train which means h-index for train dataset only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UbV30-oYtEN_",
    "outputId": "c037e06f-7a02-4ba6-c11c-4b97de217a77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 880)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 231239)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gcn_conv (GCNConv)              (None, 512)          451072      input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512)          0           gcn_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gcn_conv_1 (GCNConv)            (None, 256)          131328      dropout[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           gcn_conv_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gcn_conv_2 (GCNConv)            (None, 128)          32896       dropout_1[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           gcn_conv_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gcn_conv_3 (GCNConv)            (None, 1)            129         dropout_2[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 615,425\n",
      "Trainable params: 615,425\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gcn = GCN_model(X, y, A)\n",
    "gcn.build() #compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PO_ydWlClX8G",
    "outputId": "8cf01e19-485d-4f7a-8424-2d93084af3b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "1/1 [==============================] - 44s 44s/step - loss: 0.1132 - mae: 1.6901 - mse: 3.7173 - val_loss: 0.0431 - val_mae: 1.3058 - val_mse: 2.4028\n",
      "Epoch 2/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0888 - mae: 1.3258 - mse: 2.5802 - val_loss: 0.0226 - val_mae: 0.6847 - val_mse: 0.7280\n",
      "Epoch 3/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0500 - mae: 0.7463 - mse: 0.8835 - val_loss: 0.0378 - val_mae: 1.1447 - val_mse: 1.9643\n",
      "Epoch 4/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0741 - mae: 1.1060 - mse: 1.8693 - val_loss: 0.0255 - val_mae: 0.7717 - val_mse: 1.0139\n",
      "Epoch 5/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0539 - mae: 0.8046 - mse: 1.0940 - val_loss: 0.0226 - val_mae: 0.6862 - val_mse: 0.7264\n",
      "Epoch 6/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0513 - mae: 0.7662 - mse: 0.9198 - val_loss: 0.0261 - val_mae: 0.7920 - val_mse: 0.9272\n",
      "Epoch 7/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0582 - mae: 0.8689 - mse: 1.1551 - val_loss: 0.0233 - val_mae: 0.7075 - val_mse: 0.7614\n",
      "Epoch 8/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0535 - mae: 0.7982 - mse: 0.9866 - val_loss: 0.0217 - val_mae: 0.6588 - val_mse: 0.7234\n",
      "Epoch 9/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0485 - mae: 0.7240 - mse: 0.8534 - val_loss: 0.0247 - val_mae: 0.7482 - val_mse: 0.9555\n",
      "Epoch 10/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0509 - mae: 0.7592 - mse: 0.9689 - val_loss: 0.0261 - val_mae: 0.7906 - val_mse: 1.0578\n",
      "Epoch 11/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0528 - mae: 0.7884 - mse: 1.0445 - val_loss: 0.0242 - val_mae: 0.7342 - val_mse: 0.9202\n",
      "Epoch 12/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0502 - mae: 0.7487 - mse: 0.9447 - val_loss: 0.0220 - val_mae: 0.6675 - val_mse: 0.7504\n",
      "Epoch 13/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0480 - mae: 0.7168 - mse: 0.8394 - val_loss: 0.0215 - val_mae: 0.6520 - val_mse: 0.6859\n",
      "Epoch 14/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0475 - mae: 0.7092 - mse: 0.8086 - val_loss: 0.0220 - val_mae: 0.6656 - val_mse: 0.6933\n",
      "Epoch 15/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0490 - mae: 0.7310 - mse: 0.8432 - val_loss: 0.0219 - val_mae: 0.6634 - val_mse: 0.6895\n",
      "Epoch 16/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0490 - mae: 0.7310 - mse: 0.8390 - val_loss: 0.0214 - val_mae: 0.6494 - val_mse: 0.6801\n",
      "Epoch 17/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0477 - mae: 0.7116 - mse: 0.8028 - val_loss: 0.0216 - val_mae: 0.6555 - val_mse: 0.7165\n",
      "Epoch 18/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0467 - mae: 0.6966 - mse: 0.7971 - val_loss: 0.0224 - val_mae: 0.6775 - val_mse: 0.7772\n",
      "Epoch 19/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0471 - mae: 0.7036 - mse: 0.8221 - val_loss: 0.0228 - val_mae: 0.6896 - val_mse: 0.8083\n",
      "Epoch 20/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0475 - mae: 0.7082 - mse: 0.8443 - val_loss: 0.0224 - val_mae: 0.6797 - val_mse: 0.7829\n",
      "Epoch 21/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0471 - mae: 0.7032 - mse: 0.8279 - val_loss: 0.0217 - val_mae: 0.6582 - val_mse: 0.7244\n",
      "Epoch 22/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0464 - mae: 0.6920 - mse: 0.7927 - val_loss: 0.0213 - val_mae: 0.6465 - val_mse: 0.6803\n",
      "Epoch 23/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0457 - mae: 0.6815 - mse: 0.7583 - val_loss: 0.0216 - val_mae: 0.6532 - val_mse: 0.6752\n",
      "Epoch 24/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0464 - mae: 0.6926 - mse: 0.7704 - val_loss: 0.0218 - val_mae: 0.6591 - val_mse: 0.6806\n",
      "Epoch 25/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0465 - mae: 0.6942 - mse: 0.7677 - val_loss: 0.0216 - val_mae: 0.6530 - val_mse: 0.6740\n",
      "Epoch 26/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0460 - mae: 0.6871 - mse: 0.7525 - val_loss: 0.0213 - val_mae: 0.6452 - val_mse: 0.6733\n",
      "Epoch 27/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0456 - mae: 0.6808 - mse: 0.7527 - val_loss: 0.0214 - val_mae: 0.6483 - val_mse: 0.6955\n",
      "Epoch 28/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0454 - mae: 0.6782 - mse: 0.7638 - val_loss: 0.0216 - val_mae: 0.6537 - val_mse: 0.7121\n",
      "Epoch 29/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0458 - mae: 0.6829 - mse: 0.7780 - val_loss: 0.0215 - val_mae: 0.6503 - val_mse: 0.7024\n",
      "Epoch 30/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0456 - mae: 0.6812 - mse: 0.7723 - val_loss: 0.0212 - val_mae: 0.6435 - val_mse: 0.6773\n",
      "Epoch 31/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0451 - mae: 0.6736 - mse: 0.7427 - val_loss: 0.0213 - val_mae: 0.6448 - val_mse: 0.6647\n",
      "Epoch 32/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0451 - mae: 0.6733 - mse: 0.7332 - val_loss: 0.0215 - val_mae: 0.6518 - val_mse: 0.6681\n",
      "Epoch 33/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0452 - mae: 0.6745 - mse: 0.7312 - val_loss: 0.0216 - val_mae: 0.6543 - val_mse: 0.6703\n",
      "Epoch 34/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0450 - mae: 0.6716 - mse: 0.7248 - val_loss: 0.0214 - val_mae: 0.6472 - val_mse: 0.6632\n",
      "Epoch 35/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0449 - mae: 0.6704 - mse: 0.7276 - val_loss: 0.0212 - val_mae: 0.6413 - val_mse: 0.6634\n",
      "Epoch 36/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0447 - mae: 0.6679 - mse: 0.7286 - val_loss: 0.0212 - val_mae: 0.6410 - val_mse: 0.6716\n",
      "Epoch 37/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0450 - mae: 0.6716 - mse: 0.7439 - val_loss: 0.0211 - val_mae: 0.6403 - val_mse: 0.6703\n",
      "Epoch 38/2000\n",
      "1/1 [==============================] - 23s 23s/step - loss: 0.0447 - mae: 0.6669 - mse: 0.7361 - val_loss: 0.0211 - val_mae: 0.6388 - val_mse: 0.6593\n",
      "Epoch 39/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0445 - mae: 0.6646 - mse: 0.7281 - val_loss: 0.0212 - val_mae: 0.6417 - val_mse: 0.6539\n",
      "Epoch 40/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0445 - mae: 0.6641 - mse: 0.7169 - val_loss: 0.0213 - val_mae: 0.6463 - val_mse: 0.6561\n",
      "Epoch 41/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0446 - mae: 0.6662 - mse: 0.7135 - val_loss: 0.0212 - val_mae: 0.6438 - val_mse: 0.6528\n",
      "Epoch 42/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0446 - mae: 0.6652 - mse: 0.7133 - val_loss: 0.0210 - val_mae: 0.6371 - val_mse: 0.6481\n",
      "Epoch 43/2000\n",
      "1/1 [==============================] - 23s 23s/step - loss: 0.0443 - mae: 0.6609 - mse: 0.7107 - val_loss: 0.0209 - val_mae: 0.6345 - val_mse: 0.6523\n",
      "Epoch 44/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0445 - mae: 0.6641 - mse: 0.7223 - val_loss: 0.0209 - val_mae: 0.6335 - val_mse: 0.6494\n",
      "Epoch 45/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0442 - mae: 0.6602 - mse: 0.7160 - val_loss: 0.0209 - val_mae: 0.6339 - val_mse: 0.6423\n",
      "Epoch 46/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0440 - mae: 0.6571 - mse: 0.7060 - val_loss: 0.0210 - val_mae: 0.6371 - val_mse: 0.6413\n",
      "Epoch 47/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0440 - mae: 0.6569 - mse: 0.6983 - val_loss: 0.0211 - val_mae: 0.6379 - val_mse: 0.6408\n",
      "Epoch 48/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0440 - mae: 0.6568 - mse: 0.6957 - val_loss: 0.0209 - val_mae: 0.6333 - val_mse: 0.6361\n",
      "Epoch 49/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0440 - mae: 0.6569 - mse: 0.6959 - val_loss: 0.0208 - val_mae: 0.6288 - val_mse: 0.6350\n",
      "Epoch 50/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0438 - mae: 0.6542 - mse: 0.6984 - val_loss: 0.0207 - val_mae: 0.6275 - val_mse: 0.6352\n",
      "Epoch 51/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0436 - mae: 0.6512 - mse: 0.6966 - val_loss: 0.0207 - val_mae: 0.6271 - val_mse: 0.6296\n",
      "Epoch 52/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0436 - mae: 0.6509 - mse: 0.6897 - val_loss: 0.0208 - val_mae: 0.6292 - val_mse: 0.6271\n",
      "Epoch 53/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0436 - mae: 0.6503 - mse: 0.6863 - val_loss: 0.0208 - val_mae: 0.6289 - val_mse: 0.6254\n",
      "Epoch 54/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0434 - mae: 0.6477 - mse: 0.6770 - val_loss: 0.0206 - val_mae: 0.6256 - val_mse: 0.6227\n",
      "Epoch 55/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0432 - mae: 0.6448 - mse: 0.6759 - val_loss: 0.0206 - val_mae: 0.6230 - val_mse: 0.6215\n",
      "Epoch 56/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0432 - mae: 0.6449 - mse: 0.6797 - val_loss: 0.0205 - val_mae: 0.6222 - val_mse: 0.6184\n",
      "Epoch 57/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0432 - mae: 0.6444 - mse: 0.6745 - val_loss: 0.0206 - val_mae: 0.6230 - val_mse: 0.6155\n",
      "Epoch 58/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0431 - mae: 0.6437 - mse: 0.6723 - val_loss: 0.0205 - val_mae: 0.6221 - val_mse: 0.6130\n",
      "Epoch 59/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0429 - mae: 0.6405 - mse: 0.6664 - val_loss: 0.0204 - val_mae: 0.6183 - val_mse: 0.6099\n",
      "Epoch 60/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0430 - mae: 0.6410 - mse: 0.6700 - val_loss: 0.0203 - val_mae: 0.6161 - val_mse: 0.6070\n",
      "Epoch 61/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0428 - mae: 0.6393 - mse: 0.6659 - val_loss: 0.0203 - val_mae: 0.6149 - val_mse: 0.6033\n",
      "Epoch 62/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0428 - mae: 0.6386 - mse: 0.6600 - val_loss: 0.0203 - val_mae: 0.6144 - val_mse: 0.6002\n",
      "Epoch 63/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0426 - mae: 0.6362 - mse: 0.6561 - val_loss: 0.0202 - val_mae: 0.6112 - val_mse: 0.5968\n",
      "Epoch 64/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0424 - mae: 0.6333 - mse: 0.6540 - val_loss: 0.0201 - val_mae: 0.6084 - val_mse: 0.5949\n",
      "Epoch 65/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0423 - mae: 0.6313 - mse: 0.6518 - val_loss: 0.0201 - val_mae: 0.6083 - val_mse: 0.5902\n",
      "Epoch 66/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0423 - mae: 0.6317 - mse: 0.6451 - val_loss: 0.0200 - val_mae: 0.6067 - val_mse: 0.5870\n",
      "Epoch 67/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0421 - mae: 0.6289 - mse: 0.6421 - val_loss: 0.0199 - val_mae: 0.6029 - val_mse: 0.5853\n",
      "Epoch 68/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0422 - mae: 0.6293 - mse: 0.6445 - val_loss: 0.0198 - val_mae: 0.6011 - val_mse: 0.5830\n",
      "Epoch 69/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0419 - mae: 0.6255 - mse: 0.6354 - val_loss: 0.0199 - val_mae: 0.6038 - val_mse: 0.5795\n",
      "Epoch 70/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0419 - mae: 0.6257 - mse: 0.6311 - val_loss: 0.0197 - val_mae: 0.5979 - val_mse: 0.5785\n",
      "Epoch 71/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0418 - mae: 0.6238 - mse: 0.6321 - val_loss: 0.0197 - val_mae: 0.5964 - val_mse: 0.5765\n",
      "Epoch 72/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0416 - mae: 0.6202 - mse: 0.6273 - val_loss: 0.0198 - val_mae: 0.5995 - val_mse: 0.5730\n",
      "Epoch 73/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0417 - mae: 0.6219 - mse: 0.6241 - val_loss: 0.0196 - val_mae: 0.5940 - val_mse: 0.5741\n",
      "Epoch 74/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0414 - mae: 0.6183 - mse: 0.6232 - val_loss: 0.0196 - val_mae: 0.5927 - val_mse: 0.5685\n",
      "Epoch 75/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0416 - mae: 0.6202 - mse: 0.6240 - val_loss: 0.0196 - val_mae: 0.5929 - val_mse: 0.5662\n",
      "Epoch 76/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0415 - mae: 0.6195 - mse: 0.6198 - val_loss: 0.0195 - val_mae: 0.5916 - val_mse: 0.5734\n",
      "Epoch 77/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0414 - mae: 0.6176 - mse: 0.6206 - val_loss: 0.0195 - val_mae: 0.5912 - val_mse: 0.5636\n",
      "Epoch 78/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0413 - mae: 0.6160 - mse: 0.6148 - val_loss: 0.0194 - val_mae: 0.5887 - val_mse: 0.5624\n",
      "Epoch 79/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0411 - mae: 0.6133 - mse: 0.6132 - val_loss: 0.0195 - val_mae: 0.5895 - val_mse: 0.5717\n",
      "Epoch 80/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0410 - mae: 0.6115 - mse: 0.6140 - val_loss: 0.0195 - val_mae: 0.5897 - val_mse: 0.5609\n",
      "Epoch 81/2000\n",
      "1/1 [==============================] - 23s 23s/step - loss: 0.0412 - mae: 0.6144 - mse: 0.6091 - val_loss: 0.0195 - val_mae: 0.5905 - val_mse: 0.5758\n",
      "Epoch 82/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0410 - mae: 0.6114 - mse: 0.6156 - val_loss: 0.0194 - val_mae: 0.5866 - val_mse: 0.5580\n",
      "Epoch 83/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0410 - mae: 0.6119 - mse: 0.6037 - val_loss: 0.0193 - val_mae: 0.5849 - val_mse: 0.5612\n",
      "Epoch 84/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0406 - mae: 0.6062 - mse: 0.6004 - val_loss: 0.0193 - val_mae: 0.5859 - val_mse: 0.5657\n",
      "Epoch 85/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0408 - mae: 0.6082 - mse: 0.6050 - val_loss: 0.0194 - val_mae: 0.5888 - val_mse: 0.5581\n",
      "Epoch 86/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0409 - mae: 0.6111 - mse: 0.6055 - val_loss: 0.0199 - val_mae: 0.6015 - val_mse: 0.6013\n",
      "Epoch 87/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0412 - mae: 0.6148 - mse: 0.6245 - val_loss: 0.0194 - val_mae: 0.5891 - val_mse: 0.5577\n",
      "Epoch 88/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0410 - mae: 0.6121 - mse: 0.6060 - val_loss: 0.0193 - val_mae: 0.5835 - val_mse: 0.5602\n",
      "Epoch 89/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0405 - mae: 0.6047 - mse: 0.5971 - val_loss: 0.0194 - val_mae: 0.5890 - val_mse: 0.5739\n",
      "Epoch 90/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0406 - mae: 0.6066 - mse: 0.6034 - val_loss: 0.0194 - val_mae: 0.5880 - val_mse: 0.5558\n",
      "Epoch 91/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0409 - mae: 0.6110 - mse: 0.6015 - val_loss: 0.0192 - val_mae: 0.5832 - val_mse: 0.5599\n",
      "Epoch 92/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0405 - mae: 0.6043 - mse: 0.5961 - val_loss: 0.0193 - val_mae: 0.5857 - val_mse: 0.5669\n",
      "Epoch 93/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0405 - mae: 0.6049 - mse: 0.5974 - val_loss: 0.0193 - val_mae: 0.5842 - val_mse: 0.5513\n",
      "Epoch 94/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0404 - mae: 0.6034 - mse: 0.5914 - val_loss: 0.0192 - val_mae: 0.5818 - val_mse: 0.5578\n",
      "Epoch 95/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0402 - mae: 0.5994 - mse: 0.5905 - val_loss: 0.0192 - val_mae: 0.5833 - val_mse: 0.5625\n",
      "Epoch 96/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0404 - mae: 0.6023 - mse: 0.5960 - val_loss: 0.0193 - val_mae: 0.5838 - val_mse: 0.5498\n",
      "Epoch 97/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0404 - mae: 0.6037 - mse: 0.5897 - val_loss: 0.0193 - val_mae: 0.5860 - val_mse: 0.5699\n",
      "Epoch 98/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0403 - mae: 0.6011 - mse: 0.5937 - val_loss: 0.0190 - val_mae: 0.5772 - val_mse: 0.5465\n",
      "Epoch 99/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0400 - mae: 0.5969 - mse: 0.5801 - val_loss: 0.0190 - val_mae: 0.5769 - val_mse: 0.5439\n",
      "Epoch 100/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0399 - mae: 0.5959 - mse: 0.5801 - val_loss: 0.0193 - val_mae: 0.5855 - val_mse: 0.5699\n",
      "Epoch 101/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0402 - mae: 0.6006 - mse: 0.5960 - val_loss: 0.0191 - val_mae: 0.5787 - val_mse: 0.5433\n",
      "Epoch 102/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0402 - mae: 0.6001 - mse: 0.5836 - val_loss: 0.0191 - val_mae: 0.5785 - val_mse: 0.5552\n",
      "Epoch 103/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0401 - mae: 0.5981 - mse: 0.5874 - val_loss: 0.0190 - val_mae: 0.5744 - val_mse: 0.5441\n",
      "Epoch 104/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0397 - mae: 0.5927 - mse: 0.5761 - val_loss: 0.0189 - val_mae: 0.5740 - val_mse: 0.5395\n",
      "Epoch 105/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0398 - mae: 0.5946 - mse: 0.5741 - val_loss: 0.0192 - val_mae: 0.5812 - val_mse: 0.5618\n",
      "Epoch 106/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0399 - mae: 0.5958 - mse: 0.5850 - val_loss: 0.0189 - val_mae: 0.5742 - val_mse: 0.5379\n",
      "Epoch 107/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0399 - mae: 0.5953 - mse: 0.5774 - val_loss: 0.0190 - val_mae: 0.5745 - val_mse: 0.5472\n",
      "Epoch 108/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0396 - mae: 0.5907 - mse: 0.5713 - val_loss: 0.0189 - val_mae: 0.5722 - val_mse: 0.5414\n",
      "Epoch 109/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0395 - mae: 0.5898 - mse: 0.5712 - val_loss: 0.0188 - val_mae: 0.5706 - val_mse: 0.5354\n",
      "Epoch 110/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0393 - mae: 0.5870 - mse: 0.5631 - val_loss: 0.0190 - val_mae: 0.5746 - val_mse: 0.5491\n",
      "Epoch 111/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0398 - mae: 0.5933 - mse: 0.5772 - val_loss: 0.0189 - val_mae: 0.5714 - val_mse: 0.5331\n",
      "Epoch 112/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0398 - mae: 0.5939 - mse: 0.5726 - val_loss: 0.0195 - val_mae: 0.5904 - val_mse: 0.5814\n",
      "Epoch 113/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0402 - mae: 0.6005 - mse: 0.5956 - val_loss: 0.0194 - val_mae: 0.5893 - val_mse: 0.5548\n",
      "Epoch 114/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0410 - mae: 0.6115 - mse: 0.6002 - val_loss: 0.0204 - val_mae: 0.6184 - val_mse: 0.6345\n",
      "Epoch 115/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0416 - mae: 0.6202 - mse: 0.6373 - val_loss: 0.0190 - val_mae: 0.5746 - val_mse: 0.5349\n",
      "Epoch 116/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0397 - mae: 0.5922 - mse: 0.5693 - val_loss: 0.0189 - val_mae: 0.5712 - val_mse: 0.5320\n",
      "Epoch 117/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0394 - mae: 0.5877 - mse: 0.5644 - val_loss: 0.0198 - val_mae: 0.5998 - val_mse: 0.5996\n",
      "Epoch 118/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0406 - mae: 0.6053 - mse: 0.6045 - val_loss: 0.0189 - val_mae: 0.5716 - val_mse: 0.5334\n",
      "Epoch 119/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0394 - mae: 0.5884 - mse: 0.5654 - val_loss: 0.0189 - val_mae: 0.5733 - val_mse: 0.5341\n",
      "Epoch 120/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0395 - mae: 0.5892 - mse: 0.5648 - val_loss: 0.0196 - val_mae: 0.5929 - val_mse: 0.5860\n",
      "Epoch 121/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0401 - mae: 0.5986 - mse: 0.5923 - val_loss: 0.0188 - val_mae: 0.5707 - val_mse: 0.5382\n",
      "Epoch 122/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0392 - mae: 0.5844 - mse: 0.5592 - val_loss: 0.0189 - val_mae: 0.5734 - val_mse: 0.5334\n",
      "Epoch 123/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0396 - mae: 0.5908 - mse: 0.5674 - val_loss: 0.0191 - val_mae: 0.5797 - val_mse: 0.5607\n",
      "Epoch 124/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0393 - mae: 0.5869 - mse: 0.5691 - val_loss: 0.0189 - val_mae: 0.5722 - val_mse: 0.5455\n",
      "Epoch 125/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0391 - mae: 0.5836 - mse: 0.5602 - val_loss: 0.0189 - val_mae: 0.5726 - val_mse: 0.5320\n",
      "Epoch 126/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0396 - mae: 0.5909 - mse: 0.5680 - val_loss: 0.0191 - val_mae: 0.5784 - val_mse: 0.5593\n",
      "Epoch 127/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0392 - mae: 0.5856 - mse: 0.5662 - val_loss: 0.0187 - val_mae: 0.5666 - val_mse: 0.5348\n",
      "Epoch 128/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0388 - mae: 0.5788 - mse: 0.5512 - val_loss: 0.0187 - val_mae: 0.5662 - val_mse: 0.5254\n",
      "Epoch 129/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0393 - mae: 0.5862 - mse: 0.5606 - val_loss: 0.0192 - val_mae: 0.5814 - val_mse: 0.5656\n",
      "Epoch 130/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0395 - mae: 0.5897 - mse: 0.5749 - val_loss: 0.0186 - val_mae: 0.5629 - val_mse: 0.5230\n",
      "Epoch 131/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0390 - mae: 0.5823 - mse: 0.5532 - val_loss: 0.0185 - val_mae: 0.5620 - val_mse: 0.5237\n",
      "Epoch 132/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0387 - mae: 0.5772 - mse: 0.5500 - val_loss: 0.0190 - val_mae: 0.5757 - val_mse: 0.5541\n",
      "Epoch 133/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0392 - mae: 0.5845 - mse: 0.5650 - val_loss: 0.0187 - val_mae: 0.5661 - val_mse: 0.5232\n",
      "Epoch 134/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0392 - mae: 0.5848 - mse: 0.5584 - val_loss: 0.0187 - val_mae: 0.5679 - val_mse: 0.5382\n",
      "Epoch 135/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0389 - mae: 0.5808 - mse: 0.5547 - val_loss: 0.0186 - val_mae: 0.5625 - val_mse: 0.5266\n",
      "Epoch 136/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0388 - mae: 0.5786 - mse: 0.5501 - val_loss: 0.0185 - val_mae: 0.5606 - val_mse: 0.5179\n",
      "Epoch 137/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0389 - mae: 0.5802 - mse: 0.5498 - val_loss: 0.0191 - val_mae: 0.5777 - val_mse: 0.5573\n",
      "Epoch 138/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0391 - mae: 0.5830 - mse: 0.5630 - val_loss: 0.0186 - val_mae: 0.5629 - val_mse: 0.5185\n",
      "Epoch 139/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0390 - mae: 0.5825 - mse: 0.5522 - val_loss: 0.0188 - val_mae: 0.5710 - val_mse: 0.5447\n",
      "Epoch 140/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0388 - mae: 0.5788 - mse: 0.5552 - val_loss: 0.0184 - val_mae: 0.5578 - val_mse: 0.5164\n",
      "Epoch 141/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0387 - mae: 0.5769 - mse: 0.5446 - val_loss: 0.0184 - val_mae: 0.5571 - val_mse: 0.5153\n",
      "Epoch 142/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0385 - mae: 0.5743 - mse: 0.5422 - val_loss: 0.0188 - val_mae: 0.5697 - val_mse: 0.5429\n",
      "Epoch 143/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0387 - mae: 0.5780 - mse: 0.5538 - val_loss: 0.0185 - val_mae: 0.5615 - val_mse: 0.5164\n",
      "Epoch 144/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0391 - mae: 0.5832 - mse: 0.5542 - val_loss: 0.0193 - val_mae: 0.5845 - val_mse: 0.5704\n",
      "Epoch 145/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0391 - mae: 0.5838 - mse: 0.5670 - val_loss: 0.0188 - val_mae: 0.5684 - val_mse: 0.5244\n",
      "Epoch 146/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0396 - mae: 0.5916 - mse: 0.5661 - val_loss: 0.0195 - val_mae: 0.5908 - val_mse: 0.5821\n",
      "Epoch 147/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0394 - mae: 0.5883 - mse: 0.5753 - val_loss: 0.0185 - val_mae: 0.5607 - val_mse: 0.5149\n",
      "Epoch 148/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0388 - mae: 0.5795 - mse: 0.5497 - val_loss: 0.0185 - val_mae: 0.5595 - val_mse: 0.5229\n",
      "Epoch 149/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0382 - mae: 0.5700 - mse: 0.5360 - val_loss: 0.0188 - val_mae: 0.5683 - val_mse: 0.5404\n",
      "Epoch 150/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0387 - mae: 0.5769 - mse: 0.5510 - val_loss: 0.0185 - val_mae: 0.5609 - val_mse: 0.5148\n",
      "Epoch 151/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0389 - mae: 0.5806 - mse: 0.5503 - val_loss: 0.0188 - val_mae: 0.5691 - val_mse: 0.5421\n",
      "Epoch 152/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0385 - mae: 0.5747 - mse: 0.5476 - val_loss: 0.0184 - val_mae: 0.5567 - val_mse: 0.5173\n",
      "Epoch 153/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0382 - mae: 0.5700 - mse: 0.5354 - val_loss: 0.0183 - val_mae: 0.5549 - val_mse: 0.5098\n",
      "Epoch 154/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0382 - mae: 0.5707 - mse: 0.5344 - val_loss: 0.0190 - val_mae: 0.5753 - val_mse: 0.5545\n",
      "Epoch 155/2000\n",
      "1/1 [==============================] - 23s 23s/step - loss: 0.0386 - mae: 0.5768 - mse: 0.5550 - val_loss: 0.0184 - val_mae: 0.5585 - val_mse: 0.5120\n",
      "Epoch 156/2000\n",
      "1/1 [==============================] - 23s 23s/step - loss: 0.0387 - mae: 0.5782 - mse: 0.5461 - val_loss: 0.0188 - val_mae: 0.5685 - val_mse: 0.5421\n",
      "Epoch 157/2000\n",
      "1/1 [==============================] - 23s 23s/step - loss: 0.0385 - mae: 0.5745 - mse: 0.5456 - val_loss: 0.0182 - val_mae: 0.5524 - val_mse: 0.5094\n",
      "Epoch 158/2000\n",
      "1/1 [==============================] - 23s 23s/step - loss: 0.0381 - mae: 0.5690 - mse: 0.5340 - val_loss: 0.0182 - val_mae: 0.5520 - val_mse: 0.5090\n",
      "Epoch 159/2000\n",
      "1/1 [==============================] - 23s 23s/step - loss: 0.0379 - mae: 0.5654 - mse: 0.5280 - val_loss: 0.0186 - val_mae: 0.5637 - val_mse: 0.5334\n",
      "Epoch 160/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0381 - mae: 0.5693 - mse: 0.5390 - val_loss: 0.0183 - val_mae: 0.5548 - val_mse: 0.5072\n",
      "Epoch 161/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0385 - mae: 0.5746 - mse: 0.5411 - val_loss: 0.0194 - val_mae: 0.5878 - val_mse: 0.5769\n",
      "Epoch 162/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0391 - mae: 0.5832 - mse: 0.5672 - val_loss: 0.0188 - val_mae: 0.5693 - val_mse: 0.5243\n",
      "Epoch 163/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0398 - mae: 0.5941 - mse: 0.5708 - val_loss: 0.0196 - val_mae: 0.5937 - val_mse: 0.5872\n",
      "Epoch 164/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0395 - mae: 0.5891 - mse: 0.5781 - val_loss: 0.0182 - val_mae: 0.5520 - val_mse: 0.5054\n",
      "Epoch 165/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0382 - mae: 0.5695 - mse: 0.5317 - val_loss: 0.0182 - val_mae: 0.5530 - val_mse: 0.5061\n",
      "Epoch 166/2000\n",
      "1/1 [==============================] - 23s 23s/step - loss: 0.0382 - mae: 0.5697 - mse: 0.5314 - val_loss: 0.0193 - val_mae: 0.5861 - val_mse: 0.5741\n",
      "Epoch 167/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0390 - mae: 0.5819 - mse: 0.5614 - val_loss: 0.0183 - val_mae: 0.5540 - val_mse: 0.5065\n",
      "Epoch 168/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0383 - mae: 0.5713 - mse: 0.5343 - val_loss: 0.0183 - val_mae: 0.5531 - val_mse: 0.5079\n",
      "Epoch 169/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0380 - mae: 0.5678 - mse: 0.5292 - val_loss: 0.0189 - val_mae: 0.5733 - val_mse: 0.5503\n",
      "Epoch 170/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0383 - mae: 0.5723 - mse: 0.5436 - val_loss: 0.0182 - val_mae: 0.5522 - val_mse: 0.5042\n",
      "Epoch 171/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0381 - mae: 0.5690 - mse: 0.5317 - val_loss: 0.0182 - val_mae: 0.5527 - val_mse: 0.5116\n",
      "Epoch 172/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0377 - mae: 0.5634 - mse: 0.5254 - val_loss: 0.0187 - val_mae: 0.5662 - val_mse: 0.5382\n",
      "Epoch 173/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0382 - mae: 0.5698 - mse: 0.5396 - val_loss: 0.0183 - val_mae: 0.5545 - val_mse: 0.5058\n",
      "Epoch 174/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0386 - mae: 0.5759 - mse: 0.5428 - val_loss: 0.0189 - val_mae: 0.5722 - val_mse: 0.5497\n",
      "Epoch 175/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0382 - mae: 0.5700 - mse: 0.5412 - val_loss: 0.0181 - val_mae: 0.5482 - val_mse: 0.5004\n",
      "Epoch 176/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0378 - mae: 0.5644 - mse: 0.5242 - val_loss: 0.0182 - val_mae: 0.5527 - val_mse: 0.5141\n",
      "Epoch 177/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0376 - mae: 0.5613 - mse: 0.5236 - val_loss: 0.0182 - val_mae: 0.5510 - val_mse: 0.5108\n",
      "Epoch 178/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0375 - mae: 0.5601 - mse: 0.5195 - val_loss: 0.0181 - val_mae: 0.5470 - val_mse: 0.4981\n",
      "Epoch 179/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0376 - mae: 0.5613 - mse: 0.5234 - val_loss: 0.0189 - val_mae: 0.5718 - val_mse: 0.5486\n",
      "Epoch 180/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0383 - mae: 0.5711 - mse: 0.5418 - val_loss: 0.0184 - val_mae: 0.5577 - val_mse: 0.5083\n",
      "Epoch 181/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0389 - mae: 0.5808 - mse: 0.5500 - val_loss: 0.0195 - val_mae: 0.5914 - val_mse: 0.5828\n",
      "Epoch 182/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0393 - mae: 0.5859 - mse: 0.5684 - val_loss: 0.0182 - val_mae: 0.5530 - val_mse: 0.5019\n",
      "Epoch 183/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0384 - mae: 0.5733 - mse: 0.5367 - val_loss: 0.0183 - val_mae: 0.5537 - val_mse: 0.5141\n",
      "Epoch 184/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0375 - mae: 0.5602 - mse: 0.5211 - val_loss: 0.0185 - val_mae: 0.5607 - val_mse: 0.5269\n",
      "Epoch 185/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0377 - mae: 0.5633 - mse: 0.5291 - val_loss: 0.0182 - val_mae: 0.5512 - val_mse: 0.4996\n",
      "Epoch 186/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0382 - mae: 0.5695 - mse: 0.5303 - val_loss: 0.0185 - val_mae: 0.5613 - val_mse: 0.5283\n",
      "Epoch 187/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0377 - mae: 0.5626 - mse: 0.5275 - val_loss: 0.0181 - val_mae: 0.5490 - val_mse: 0.5043\n",
      "Epoch 188/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0375 - mae: 0.5592 - mse: 0.5172 - val_loss: 0.0180 - val_mae: 0.5467 - val_mse: 0.4960\n",
      "Epoch 189/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0376 - mae: 0.5612 - mse: 0.5190 - val_loss: 0.0186 - val_mae: 0.5640 - val_mse: 0.5342\n",
      "Epoch 190/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0378 - mae: 0.5644 - mse: 0.5329 - val_loss: 0.0180 - val_mae: 0.5459 - val_mse: 0.4948\n",
      "Epoch 191/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0377 - mae: 0.5624 - mse: 0.5196 - val_loss: 0.0182 - val_mae: 0.5528 - val_mse: 0.5147\n",
      "Epoch 192/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0373 - mae: 0.5572 - mse: 0.5172 - val_loss: 0.0179 - val_mae: 0.5436 - val_mse: 0.4963\n",
      "Epoch 193/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0372 - mae: 0.5550 - mse: 0.5113 - val_loss: 0.0181 - val_mae: 0.5470 - val_mse: 0.5042\n",
      "Epoch 194/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0370 - mae: 0.5527 - mse: 0.5111 - val_loss: 0.0179 - val_mae: 0.5435 - val_mse: 0.4970\n",
      "Epoch 195/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0372 - mae: 0.5552 - mse: 0.5132 - val_loss: 0.0179 - val_mae: 0.5438 - val_mse: 0.4979\n",
      "Epoch 196/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0371 - mae: 0.5544 - mse: 0.5128 - val_loss: 0.0179 - val_mae: 0.5417 - val_mse: 0.4934\n",
      "Epoch 197/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0370 - mae: 0.5522 - mse: 0.5084 - val_loss: 0.0180 - val_mae: 0.5469 - val_mse: 0.5040\n",
      "Epoch 198/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0373 - mae: 0.5565 - mse: 0.5158 - val_loss: 0.0179 - val_mae: 0.5424 - val_mse: 0.4897\n",
      "Epoch 199/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0375 - mae: 0.5591 - mse: 0.5155 - val_loss: 0.0202 - val_mae: 0.6114 - val_mse: 0.6157\n",
      "Epoch 200/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0400 - mae: 0.5971 - mse: 0.5888 - val_loss: 0.0227 - val_mae: 0.6874 - val_mse: 0.7218\n",
      "Epoch 201/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0486 - mae: 0.7258 - mse: 0.8234 - val_loss: 0.0226 - val_mae: 0.6835 - val_mse: 0.7524\n",
      "Epoch 202/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0444 - mae: 0.6628 - mse: 0.7152 - val_loss: 0.0187 - val_mae: 0.5670 - val_mse: 0.5392\n",
      "Epoch 203/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0379 - mae: 0.5661 - mse: 0.5327 - val_loss: 0.0202 - val_mae: 0.6132 - val_mse: 0.5839\n",
      "Epoch 204/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0430 - mae: 0.6419 - mse: 0.6486 - val_loss: 0.0185 - val_mae: 0.5604 - val_mse: 0.5129\n",
      "Epoch 205/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0384 - mae: 0.5735 - mse: 0.5346 - val_loss: 0.0211 - val_mae: 0.6400 - val_mse: 0.6798\n",
      "Epoch 206/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0419 - mae: 0.6248 - mse: 0.6500 - val_loss: 0.0196 - val_mae: 0.5951 - val_mse: 0.5913\n",
      "Epoch 207/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0395 - mae: 0.5893 - mse: 0.5772 - val_loss: 0.0191 - val_mae: 0.5788 - val_mse: 0.5310\n",
      "Epoch 208/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0403 - mae: 0.6019 - mse: 0.5746 - val_loss: 0.0191 - val_mae: 0.5801 - val_mse: 0.5329\n",
      "Epoch 209/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0404 - mae: 0.6036 - mse: 0.5802 - val_loss: 0.0192 - val_mae: 0.5813 - val_mse: 0.5633\n",
      "Epoch 210/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0392 - mae: 0.5848 - mse: 0.5627 - val_loss: 0.0203 - val_mae: 0.6163 - val_mse: 0.6323\n",
      "Epoch 211/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0406 - mae: 0.6056 - mse: 0.6085 - val_loss: 0.0186 - val_mae: 0.5623 - val_mse: 0.5232\n",
      "Epoch 212/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0383 - mae: 0.5712 - mse: 0.5362 - val_loss: 0.0189 - val_mae: 0.5733 - val_mse: 0.5250\n",
      "Epoch 213/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0400 - mae: 0.5977 - mse: 0.5731 - val_loss: 0.0183 - val_mae: 0.5556 - val_mse: 0.5082\n",
      "Epoch 214/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0382 - mae: 0.5696 - mse: 0.5301 - val_loss: 0.0196 - val_mae: 0.5935 - val_mse: 0.5875\n",
      "Epoch 215/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0394 - mae: 0.5884 - mse: 0.5730 - val_loss: 0.0189 - val_mae: 0.5715 - val_mse: 0.5463\n",
      "Epoch 216/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0384 - mae: 0.5731 - mse: 0.5440 - val_loss: 0.0184 - val_mae: 0.5588 - val_mse: 0.5081\n",
      "Epoch 217/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0389 - mae: 0.5805 - mse: 0.5445 - val_loss: 0.0183 - val_mae: 0.5532 - val_mse: 0.5035\n",
      "Epoch 218/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0383 - mae: 0.5715 - mse: 0.5318 - val_loss: 0.0191 - val_mae: 0.5783 - val_mse: 0.5605\n",
      "Epoch 219/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0386 - mae: 0.5757 - mse: 0.5518 - val_loss: 0.0188 - val_mae: 0.5689 - val_mse: 0.5430\n",
      "Epoch 220/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0382 - mae: 0.5706 - mse: 0.5413 - val_loss: 0.0184 - val_mae: 0.5564 - val_mse: 0.5059\n",
      "Epoch 221/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0387 - mae: 0.5783 - mse: 0.5429 - val_loss: 0.0182 - val_mae: 0.5517 - val_mse: 0.5022\n",
      "Epoch 222/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0382 - mae: 0.5698 - mse: 0.5305 - val_loss: 0.0189 - val_mae: 0.5736 - val_mse: 0.5524\n",
      "Epoch 223/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0385 - mae: 0.5752 - mse: 0.5514 - val_loss: 0.0185 - val_mae: 0.5595 - val_mse: 0.5253\n",
      "Epoch 224/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0378 - mae: 0.5647 - mse: 0.5289 - val_loss: 0.0183 - val_mae: 0.5551 - val_mse: 0.5041\n",
      "Epoch 225/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0383 - mae: 0.5710 - mse: 0.5345 - val_loss: 0.0181 - val_mae: 0.5496 - val_mse: 0.5005\n",
      "Epoch 226/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0377 - mae: 0.5621 - mse: 0.5211 - val_loss: 0.0187 - val_mae: 0.5662 - val_mse: 0.5382\n",
      "Epoch 227/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0383 - mae: 0.5717 - mse: 0.5462 - val_loss: 0.0182 - val_mae: 0.5529 - val_mse: 0.5121\n",
      "Epoch 228/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0376 - mae: 0.5616 - mse: 0.5230 - val_loss: 0.0182 - val_mae: 0.5516 - val_mse: 0.4999\n",
      "Epoch 229/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0379 - mae: 0.5651 - mse: 0.5241 - val_loss: 0.0181 - val_mae: 0.5481 - val_mse: 0.5000\n",
      "Epoch 230/2000\n",
      "1/1 [==============================] - 25s 25s/step - loss: 0.0375 - mae: 0.5594 - mse: 0.5167 - val_loss: 0.0185 - val_mae: 0.5608 - val_mse: 0.5271\n",
      "Epoch 231/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0378 - mae: 0.5645 - mse: 0.5320 - val_loss: 0.0181 - val_mae: 0.5487 - val_mse: 0.5026\n",
      "Epoch 232/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0374 - mae: 0.5584 - mse: 0.5153 - val_loss: 0.0181 - val_mae: 0.5489 - val_mse: 0.4966\n",
      "Epoch 233/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0378 - mae: 0.5646 - mse: 0.5214 - val_loss: 0.0181 - val_mae: 0.5479 - val_mse: 0.5014\n",
      "Epoch 234/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0376 - mae: 0.5608 - mse: 0.5187 - val_loss: 0.0184 - val_mae: 0.5563 - val_mse: 0.5187\n",
      "Epoch 235/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0374 - mae: 0.5582 - mse: 0.5203 - val_loss: 0.0180 - val_mae: 0.5450 - val_mse: 0.4948\n",
      "Epoch 236/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0372 - mae: 0.5556 - mse: 0.5094 - val_loss: 0.0180 - val_mae: 0.5444 - val_mse: 0.4926\n",
      "Epoch 237/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0374 - mae: 0.5581 - mse: 0.5153 - val_loss: 0.0182 - val_mae: 0.5528 - val_mse: 0.5127\n",
      "Epoch 238/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0373 - mae: 0.5562 - mse: 0.5179 - val_loss: 0.0180 - val_mae: 0.5448 - val_mse: 0.4973\n",
      "Epoch 239/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0372 - mae: 0.5549 - mse: 0.5088 - val_loss: 0.0179 - val_mae: 0.5434 - val_mse: 0.4910\n",
      "Epoch 240/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0373 - mae: 0.5572 - mse: 0.5120 - val_loss: 0.0181 - val_mae: 0.5476 - val_mse: 0.5036\n",
      "Epoch 241/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0371 - mae: 0.5537 - mse: 0.5112 - val_loss: 0.0180 - val_mae: 0.5461 - val_mse: 0.5009\n",
      "Epoch 242/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0369 - mae: 0.5511 - mse: 0.5074 - val_loss: 0.0179 - val_mae: 0.5423 - val_mse: 0.4899\n",
      "Epoch 243/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0371 - mae: 0.5544 - mse: 0.5100 - val_loss: 0.0179 - val_mae: 0.5434 - val_mse: 0.4957\n",
      "Epoch 244/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0372 - mae: 0.5556 - mse: 0.5123 - val_loss: 0.0180 - val_mae: 0.5465 - val_mse: 0.5020\n",
      "Epoch 245/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0371 - mae: 0.5541 - mse: 0.5116 - val_loss: 0.0179 - val_mae: 0.5409 - val_mse: 0.4885\n",
      "Epoch 246/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0370 - mae: 0.5527 - mse: 0.5072 - val_loss: 0.0179 - val_mae: 0.5432 - val_mse: 0.4955\n",
      "Epoch 247/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0371 - mae: 0.5534 - mse: 0.5091 - val_loss: 0.0179 - val_mae: 0.5420 - val_mse: 0.4931\n",
      "Epoch 248/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0369 - mae: 0.5509 - mse: 0.5052 - val_loss: 0.0178 - val_mae: 0.5397 - val_mse: 0.4871\n",
      "Epoch 249/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0370 - mae: 0.5518 - mse: 0.5053 - val_loss: 0.0179 - val_mae: 0.5436 - val_mse: 0.4963\n",
      "Epoch 250/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0369 - mae: 0.5508 - mse: 0.5050 - val_loss: 0.0178 - val_mae: 0.5397 - val_mse: 0.4883\n",
      "Epoch 251/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0369 - mae: 0.5513 - mse: 0.5041 - val_loss: 0.0178 - val_mae: 0.5387 - val_mse: 0.4849\n",
      "Epoch 252/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0370 - mae: 0.5516 - mse: 0.5046 - val_loss: 0.0180 - val_mae: 0.5456 - val_mse: 0.5000\n",
      "Epoch 253/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0370 - mae: 0.5518 - mse: 0.5080 - val_loss: 0.0178 - val_mae: 0.5380 - val_mse: 0.4844\n",
      "Epoch 254/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0369 - mae: 0.5501 - mse: 0.5030 - val_loss: 0.0178 - val_mae: 0.5383 - val_mse: 0.4858\n",
      "Epoch 255/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0368 - mae: 0.5497 - mse: 0.5011 - val_loss: 0.0179 - val_mae: 0.5411 - val_mse: 0.4917\n",
      "Epoch 256/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0368 - mae: 0.5486 - mse: 0.5007 - val_loss: 0.0177 - val_mae: 0.5371 - val_mse: 0.4823\n",
      "Epoch 257/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0368 - mae: 0.5488 - mse: 0.4997 - val_loss: 0.0179 - val_mae: 0.5436 - val_mse: 0.4967\n",
      "Epoch 258/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0368 - mae: 0.5488 - mse: 0.5055 - val_loss: 0.0177 - val_mae: 0.5367 - val_mse: 0.4811\n",
      "Epoch 259/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0368 - mae: 0.5493 - mse: 0.5006 - val_loss: 0.0181 - val_mae: 0.5487 - val_mse: 0.5060\n",
      "Epoch 260/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0370 - mae: 0.5521 - mse: 0.5095 - val_loss: 0.0178 - val_mae: 0.5397 - val_mse: 0.4828\n",
      "Epoch 261/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0371 - mae: 0.5536 - mse: 0.5072 - val_loss: 0.0185 - val_mae: 0.5615 - val_mse: 0.5287\n",
      "Epoch 262/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0375 - mae: 0.5599 - mse: 0.5238 - val_loss: 0.0181 - val_mae: 0.5497 - val_mse: 0.4941\n",
      "Epoch 263/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0379 - mae: 0.5656 - mse: 0.5233 - val_loss: 0.0187 - val_mae: 0.5681 - val_mse: 0.5404\n",
      "Epoch 264/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0379 - mae: 0.5657 - mse: 0.5348 - val_loss: 0.0179 - val_mae: 0.5411 - val_mse: 0.4834\n",
      "Epoch 265/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0372 - mae: 0.5546 - mse: 0.5086 - val_loss: 0.0179 - val_mae: 0.5426 - val_mse: 0.4949\n",
      "Epoch 266/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0368 - mae: 0.5498 - mse: 0.5040 - val_loss: 0.0178 - val_mae: 0.5380 - val_mse: 0.4856\n",
      "Epoch 267/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0366 - mae: 0.5456 - mse: 0.4950 - val_loss: 0.0177 - val_mae: 0.5363 - val_mse: 0.4796\n",
      "Epoch 268/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0366 - mae: 0.5464 - mse: 0.4967 - val_loss: 0.0180 - val_mae: 0.5454 - val_mse: 0.5004\n",
      "Epoch 269/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0369 - mae: 0.5502 - mse: 0.5053 - val_loss: 0.0177 - val_mae: 0.5358 - val_mse: 0.4788\n",
      "Epoch 270/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0369 - mae: 0.5504 - mse: 0.5012 - val_loss: 0.0179 - val_mae: 0.5439 - val_mse: 0.4981\n",
      "Epoch 271/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0367 - mae: 0.5480 - mse: 0.5026 - val_loss: 0.0176 - val_mae: 0.5345 - val_mse: 0.4795\n",
      "Epoch 272/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0366 - mae: 0.5463 - mse: 0.4940 - val_loss: 0.0177 - val_mae: 0.5350 - val_mse: 0.4813\n",
      "Epoch 273/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0364 - mae: 0.5428 - mse: 0.4925 - val_loss: 0.0178 - val_mae: 0.5388 - val_mse: 0.4895\n",
      "Epoch 274/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0364 - mae: 0.5438 - mse: 0.4947 - val_loss: 0.0177 - val_mae: 0.5354 - val_mse: 0.4781\n",
      "Epoch 275/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0367 - mae: 0.5475 - mse: 0.5004 - val_loss: 0.0185 - val_mae: 0.5613 - val_mse: 0.5292\n",
      "Epoch 276/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0375 - mae: 0.5591 - mse: 0.5216 - val_loss: 0.0184 - val_mae: 0.5586 - val_mse: 0.5069\n",
      "Epoch 277/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0387 - mae: 0.5779 - mse: 0.5453 - val_loss: 0.0207 - val_mae: 0.6275 - val_mse: 0.6444\n",
      "Epoch 278/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0410 - mae: 0.6124 - mse: 0.6185 - val_loss: 0.0190 - val_mae: 0.5750 - val_mse: 0.5291\n",
      "Epoch 279/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0399 - mae: 0.5953 - mse: 0.5718 - val_loss: 0.0184 - val_mae: 0.5565 - val_mse: 0.5201\n",
      "Epoch 280/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0372 - mae: 0.5550 - mse: 0.5155 - val_loss: 0.0180 - val_mae: 0.5448 - val_mse: 0.4987\n",
      "Epoch 281/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0366 - mae: 0.5470 - mse: 0.4983 - val_loss: 0.0182 - val_mae: 0.5519 - val_mse: 0.4940\n",
      "Epoch 282/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0381 - mae: 0.5691 - mse: 0.5285 - val_loss: 0.0184 - val_mae: 0.5580 - val_mse: 0.5228\n",
      "Epoch 283/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0373 - mae: 0.5571 - mse: 0.5190 - val_loss: 0.0179 - val_mae: 0.5434 - val_mse: 0.4952\n",
      "Epoch 284/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0366 - mae: 0.5458 - mse: 0.4967 - val_loss: 0.0180 - val_mae: 0.5462 - val_mse: 0.4871\n",
      "Epoch 285/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0375 - mae: 0.5602 - mse: 0.5139 - val_loss: 0.0182 - val_mae: 0.5523 - val_mse: 0.5127\n",
      "Epoch 286/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0369 - mae: 0.5501 - mse: 0.5070 - val_loss: 0.0180 - val_mae: 0.5445 - val_mse: 0.4988\n",
      "Epoch 287/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0367 - mae: 0.5483 - mse: 0.5023 - val_loss: 0.0181 - val_mae: 0.5474 - val_mse: 0.4894\n",
      "Epoch 288/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0378 - mae: 0.5647 - mse: 0.5213 - val_loss: 0.0183 - val_mae: 0.5533 - val_mse: 0.5156\n",
      "Epoch 289/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0370 - mae: 0.5524 - mse: 0.5107 - val_loss: 0.0179 - val_mae: 0.5413 - val_mse: 0.4942\n",
      "Epoch 290/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0366 - mae: 0.5465 - mse: 0.4980 - val_loss: 0.0180 - val_mae: 0.5449 - val_mse: 0.4878\n",
      "Epoch 291/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0377 - mae: 0.5627 - mse: 0.5185 - val_loss: 0.0186 - val_mae: 0.5626 - val_mse: 0.5322\n",
      "Epoch 292/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0375 - mae: 0.5592 - mse: 0.5229 - val_loss: 0.0177 - val_mae: 0.5350 - val_mse: 0.4812\n",
      "Epoch 293/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0362 - mae: 0.5407 - mse: 0.4878 - val_loss: 0.0178 - val_mae: 0.5403 - val_mse: 0.4821\n",
      "Epoch 294/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0373 - mae: 0.5563 - mse: 0.5106 - val_loss: 0.0186 - val_mae: 0.5648 - val_mse: 0.5355\n",
      "Epoch 295/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0375 - mae: 0.5593 - mse: 0.5244 - val_loss: 0.0176 - val_mae: 0.5328 - val_mse: 0.4758\n",
      "Epoch 296/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0364 - mae: 0.5436 - mse: 0.4919 - val_loss: 0.0176 - val_mae: 0.5335 - val_mse: 0.4745\n",
      "Epoch 297/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0366 - mae: 0.5459 - mse: 0.4915 - val_loss: 0.0184 - val_mae: 0.5590 - val_mse: 0.5247\n",
      "Epoch 298/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0372 - mae: 0.5552 - mse: 0.5157 - val_loss: 0.0176 - val_mae: 0.5336 - val_mse: 0.4739\n",
      "Epoch 299/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0365 - mae: 0.5441 - mse: 0.4919 - val_loss: 0.0176 - val_mae: 0.5323 - val_mse: 0.4734\n",
      "Epoch 300/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0364 - mae: 0.5426 - mse: 0.4900 - val_loss: 0.0183 - val_mae: 0.5549 - val_mse: 0.5172\n",
      "Epoch 301/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0371 - mae: 0.5533 - mse: 0.5141 - val_loss: 0.0176 - val_mae: 0.5344 - val_mse: 0.4739\n",
      "Epoch 302/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0366 - mae: 0.5461 - mse: 0.4934 - val_loss: 0.0176 - val_mae: 0.5344 - val_mse: 0.4796\n",
      "Epoch 303/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0363 - mae: 0.5415 - mse: 0.4890 - val_loss: 0.0178 - val_mae: 0.5380 - val_mse: 0.4870\n",
      "Epoch 304/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0363 - mae: 0.5415 - mse: 0.4898 - val_loss: 0.0176 - val_mae: 0.5323 - val_mse: 0.4720\n",
      "Epoch 305/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0365 - mae: 0.5449 - mse: 0.4915 - val_loss: 0.0179 - val_mae: 0.5427 - val_mse: 0.4957\n",
      "Epoch 306/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0363 - mae: 0.5419 - mse: 0.4926 - val_loss: 0.0175 - val_mae: 0.5306 - val_mse: 0.4719\n",
      "Epoch 307/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0362 - mae: 0.5401 - mse: 0.4859 - val_loss: 0.0176 - val_mae: 0.5320 - val_mse: 0.4760\n",
      "Epoch 308/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0359 - mae: 0.5360 - mse: 0.4838 - val_loss: 0.0177 - val_mae: 0.5358 - val_mse: 0.4837\n",
      "Epoch 309/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0360 - mae: 0.5380 - mse: 0.4863 - val_loss: 0.0175 - val_mae: 0.5312 - val_mse: 0.4713\n",
      "Epoch 310/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0365 - mae: 0.5442 - mse: 0.4919 - val_loss: 0.0181 - val_mae: 0.5470 - val_mse: 0.5038\n",
      "Epoch 311/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0366 - mae: 0.5456 - mse: 0.4988 - val_loss: 0.0176 - val_mae: 0.5338 - val_mse: 0.4734\n",
      "Epoch 312/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0365 - mae: 0.5450 - mse: 0.4935 - val_loss: 0.0181 - val_mae: 0.5490 - val_mse: 0.5073\n",
      "Epoch 313/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0366 - mae: 0.5458 - mse: 0.5014 - val_loss: 0.0175 - val_mae: 0.5315 - val_mse: 0.4705\n",
      "Epoch 314/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0363 - mae: 0.5419 - mse: 0.4895 - val_loss: 0.0177 - val_mae: 0.5358 - val_mse: 0.4838\n",
      "Epoch 315/2000\n",
      "1/1 [==============================] - 23s 23s/step - loss: 0.0362 - mae: 0.5407 - mse: 0.4900 - val_loss: 0.0175 - val_mae: 0.5310 - val_mse: 0.4742\n",
      "Epoch 316/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0358 - mae: 0.5347 - mse: 0.4802 - val_loss: 0.0175 - val_mae: 0.5294 - val_mse: 0.4694\n",
      "Epoch 317/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0361 - mae: 0.5389 - mse: 0.4820 - val_loss: 0.0178 - val_mae: 0.5407 - val_mse: 0.4927\n",
      "Epoch 318/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0362 - mae: 0.5409 - mse: 0.4916 - val_loss: 0.0175 - val_mae: 0.5306 - val_mse: 0.4691\n",
      "Epoch 319/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0363 - mae: 0.5423 - mse: 0.4883 - val_loss: 0.0179 - val_mae: 0.5428 - val_mse: 0.4967\n",
      "Epoch 320/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0363 - mae: 0.5415 - mse: 0.4931 - val_loss: 0.0175 - val_mae: 0.5302 - val_mse: 0.4688\n",
      "Epoch 321/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0364 - mae: 0.5438 - mse: 0.4874 - val_loss: 0.0179 - val_mae: 0.5428 - val_mse: 0.4969\n",
      "Epoch 322/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0364 - mae: 0.5436 - mse: 0.4946 - val_loss: 0.0175 - val_mae: 0.5299 - val_mse: 0.4686\n",
      "Epoch 323/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0363 - mae: 0.5412 - mse: 0.4854 - val_loss: 0.0177 - val_mae: 0.5354 - val_mse: 0.4836\n",
      "Epoch 324/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0360 - mae: 0.5370 - mse: 0.4860 - val_loss: 0.0175 - val_mae: 0.5290 - val_mse: 0.4706\n",
      "Epoch 325/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0359 - mae: 0.5359 - mse: 0.4799 - val_loss: 0.0174 - val_mae: 0.5283 - val_mse: 0.4687\n",
      "Epoch 326/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0358 - mae: 0.5349 - mse: 0.4790 - val_loss: 0.0179 - val_mae: 0.5422 - val_mse: 0.4957\n",
      "Epoch 327/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0363 - mae: 0.5411 - mse: 0.4916 - val_loss: 0.0177 - val_mae: 0.5357 - val_mse: 0.4744\n",
      "Epoch 328/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0367 - mae: 0.5482 - mse: 0.4981 - val_loss: 0.0191 - val_mae: 0.5782 - val_mse: 0.5576\n",
      "Epoch 329/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0380 - mae: 0.5674 - mse: 0.5387 - val_loss: 0.0183 - val_mae: 0.5545 - val_mse: 0.4981\n",
      "Epoch 330/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0384 - mae: 0.5736 - mse: 0.5352 - val_loss: 0.0190 - val_mae: 0.5749 - val_mse: 0.5527\n",
      "Epoch 331/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0379 - mae: 0.5660 - mse: 0.5367 - val_loss: 0.0175 - val_mae: 0.5298 - val_mse: 0.4676\n",
      "Epoch 332/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0360 - mae: 0.5380 - mse: 0.4798 - val_loss: 0.0175 - val_mae: 0.5307 - val_mse: 0.4684\n",
      "Epoch 333/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0362 - mae: 0.5397 - mse: 0.4820 - val_loss: 0.0186 - val_mae: 0.5629 - val_mse: 0.5323\n",
      "Epoch 334/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0374 - mae: 0.5579 - mse: 0.5216 - val_loss: 0.0176 - val_mae: 0.5338 - val_mse: 0.4710\n",
      "Epoch 335/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0365 - mae: 0.5445 - mse: 0.4872 - val_loss: 0.0175 - val_mae: 0.5311 - val_mse: 0.4739\n",
      "Epoch 336/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0360 - mae: 0.5369 - mse: 0.4783 - val_loss: 0.0181 - val_mae: 0.5481 - val_mse: 0.5067\n",
      "Epoch 337/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0367 - mae: 0.5476 - mse: 0.5031 - val_loss: 0.0176 - val_mae: 0.5325 - val_mse: 0.4703\n",
      "Epoch 338/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0364 - mae: 0.5429 - mse: 0.4871 - val_loss: 0.0177 - val_mae: 0.5373 - val_mse: 0.4878\n",
      "Epoch 339/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0359 - mae: 0.5363 - mse: 0.4827 - val_loss: 0.0175 - val_mae: 0.5313 - val_mse: 0.4762\n",
      "Epoch 340/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0360 - mae: 0.5367 - mse: 0.4813 - val_loss: 0.0175 - val_mae: 0.5292 - val_mse: 0.4680\n",
      "Epoch 341/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0361 - mae: 0.5387 - mse: 0.4820 - val_loss: 0.0183 - val_mae: 0.5536 - val_mse: 0.5165\n",
      "Epoch 342/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0366 - mae: 0.5459 - mse: 0.5042 - val_loss: 0.0177 - val_mae: 0.5377 - val_mse: 0.4771\n",
      "Epoch 343/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0371 - mae: 0.5538 - mse: 0.5057 - val_loss: 0.0183 - val_mae: 0.5556 - val_mse: 0.5195\n",
      "Epoch 344/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0368 - mae: 0.5498 - mse: 0.5070 - val_loss: 0.0174 - val_mae: 0.5286 - val_mse: 0.4656\n",
      "Epoch 345/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0360 - mae: 0.5373 - mse: 0.4798 - val_loss: 0.0175 - val_mae: 0.5315 - val_mse: 0.4759\n",
      "Epoch 346/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0357 - mae: 0.5330 - mse: 0.4773 - val_loss: 0.0175 - val_mae: 0.5309 - val_mse: 0.4742\n",
      "Epoch 347/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0357 - mae: 0.5325 - mse: 0.4761 - val_loss: 0.0174 - val_mae: 0.5281 - val_mse: 0.4640\n",
      "Epoch 348/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0361 - mae: 0.5382 - mse: 0.4799 - val_loss: 0.0180 - val_mae: 0.5455 - val_mse: 0.5010\n",
      "Epoch 349/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0363 - mae: 0.5416 - mse: 0.4937 - val_loss: 0.0174 - val_mae: 0.5280 - val_mse: 0.4638\n",
      "Epoch 350/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0361 - mae: 0.5381 - mse: 0.4801 - val_loss: 0.0176 - val_mae: 0.5338 - val_mse: 0.4801\n",
      "Epoch 351/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0359 - mae: 0.5359 - mse: 0.4809 - val_loss: 0.0174 - val_mae: 0.5274 - val_mse: 0.4677\n",
      "Epoch 352/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0357 - mae: 0.5335 - mse: 0.4770 - val_loss: 0.0174 - val_mae: 0.5260 - val_mse: 0.4638\n",
      "Epoch 353/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0357 - mae: 0.5329 - mse: 0.4754 - val_loss: 0.0178 - val_mae: 0.5405 - val_mse: 0.4928\n",
      "Epoch 354/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0360 - mae: 0.5380 - mse: 0.4873 - val_loss: 0.0176 - val_mae: 0.5330 - val_mse: 0.4705\n",
      "Epoch 355/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0365 - mae: 0.5454 - mse: 0.4929 - val_loss: 0.0189 - val_mae: 0.5723 - val_mse: 0.5477\n",
      "Epoch 356/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0377 - mae: 0.5620 - mse: 0.5294 - val_loss: 0.0179 - val_mae: 0.5431 - val_mse: 0.4824\n",
      "Epoch 357/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0375 - mae: 0.5595 - mse: 0.5132 - val_loss: 0.0184 - val_mae: 0.5579 - val_mse: 0.5234\n",
      "Epoch 358/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0369 - mae: 0.5504 - mse: 0.5096 - val_loss: 0.0174 - val_mae: 0.5266 - val_mse: 0.4640\n",
      "Epoch 359/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0358 - mae: 0.5347 - mse: 0.4755 - val_loss: 0.0174 - val_mae: 0.5271 - val_mse: 0.4640\n",
      "Epoch 360/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0358 - mae: 0.5347 - mse: 0.4748 - val_loss: 0.0180 - val_mae: 0.5466 - val_mse: 0.5037\n",
      "Epoch 361/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0364 - mae: 0.5426 - mse: 0.4939 - val_loss: 0.0174 - val_mae: 0.5281 - val_mse: 0.4641\n",
      "Epoch 362/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0361 - mae: 0.5394 - mse: 0.4797 - val_loss: 0.0175 - val_mae: 0.5297 - val_mse: 0.4724\n",
      "Epoch 363/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0357 - mae: 0.5321 - mse: 0.4738 - val_loss: 0.0176 - val_mae: 0.5333 - val_mse: 0.4801\n",
      "Epoch 364/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0359 - mae: 0.5356 - mse: 0.4799 - val_loss: 0.0174 - val_mae: 0.5275 - val_mse: 0.4638\n",
      "Epoch 365/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0361 - mae: 0.5394 - mse: 0.4819 - val_loss: 0.0181 - val_mae: 0.5472 - val_mse: 0.5054\n",
      "Epoch 366/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0364 - mae: 0.5426 - mse: 0.4971 - val_loss: 0.0174 - val_mae: 0.5271 - val_mse: 0.4638\n",
      "Epoch 367/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0360 - mae: 0.5379 - mse: 0.4808 - val_loss: 0.0177 - val_mae: 0.5353 - val_mse: 0.4841\n",
      "Epoch 368/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0357 - mae: 0.5328 - mse: 0.4775 - val_loss: 0.0173 - val_mae: 0.5254 - val_mse: 0.4640\n",
      "Epoch 369/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0355 - mae: 0.5305 - mse: 0.4708 - val_loss: 0.0174 - val_mae: 0.5259 - val_mse: 0.4658\n",
      "Epoch 370/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0356 - mae: 0.5307 - mse: 0.4720 - val_loss: 0.0177 - val_mae: 0.5349 - val_mse: 0.4830\n",
      "Epoch 371/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0358 - mae: 0.5336 - mse: 0.4791 - val_loss: 0.0175 - val_mae: 0.5299 - val_mse: 0.4651\n",
      "Epoch 372/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0363 - mae: 0.5424 - mse: 0.4855 - val_loss: 0.0188 - val_mae: 0.5698 - val_mse: 0.5437\n",
      "Epoch 373/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0374 - mae: 0.5586 - mse: 0.5250 - val_loss: 0.0179 - val_mae: 0.5423 - val_mse: 0.4795\n",
      "Epoch 374/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0374 - mae: 0.5583 - mse: 0.5114 - val_loss: 0.0186 - val_mae: 0.5647 - val_mse: 0.5353\n",
      "Epoch 375/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0371 - mae: 0.5540 - mse: 0.5169 - val_loss: 0.0174 - val_mae: 0.5273 - val_mse: 0.4612\n",
      "Epoch 376/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0360 - mae: 0.5370 - mse: 0.4772 - val_loss: 0.0174 - val_mae: 0.5266 - val_mse: 0.4652\n",
      "Epoch 377/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0354 - mae: 0.5286 - mse: 0.4679 - val_loss: 0.0179 - val_mae: 0.5418 - val_mse: 0.4953\n",
      "Epoch 378/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0360 - mae: 0.5374 - mse: 0.4855 - val_loss: 0.0175 - val_mae: 0.5292 - val_mse: 0.4636\n",
      "Epoch 379/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0361 - mae: 0.5395 - mse: 0.4797 - val_loss: 0.0179 - val_mae: 0.5424 - val_mse: 0.4971\n",
      "Epoch 380/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0360 - mae: 0.5370 - mse: 0.4853 - val_loss: 0.0173 - val_mae: 0.5249 - val_mse: 0.4629\n",
      "Epoch 381/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0356 - mae: 0.5316 - mse: 0.4710 - val_loss: 0.0173 - val_mae: 0.5251 - val_mse: 0.4638\n",
      "Epoch 382/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0355 - mae: 0.5298 - mse: 0.4701 - val_loss: 0.0177 - val_mae: 0.5370 - val_mse: 0.4879\n",
      "Epoch 383/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0358 - mae: 0.5336 - mse: 0.4786 - val_loss: 0.0174 - val_mae: 0.5262 - val_mse: 0.4626\n",
      "Epoch 384/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0360 - mae: 0.5379 - mse: 0.4812 - val_loss: 0.0179 - val_mae: 0.5422 - val_mse: 0.4969\n",
      "Epoch 385/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0360 - mae: 0.5369 - mse: 0.4862 - val_loss: 0.0174 - val_mae: 0.5272 - val_mse: 0.4624\n",
      "Epoch 386/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0361 - mae: 0.5389 - mse: 0.4820 - val_loss: 0.0179 - val_mae: 0.5433 - val_mse: 0.4983\n",
      "Epoch 387/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0361 - mae: 0.5389 - mse: 0.4894 - val_loss: 0.0173 - val_mae: 0.5251 - val_mse: 0.4591\n",
      "Epoch 388/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0360 - mae: 0.5368 - mse: 0.4763 - val_loss: 0.0176 - val_mae: 0.5325 - val_mse: 0.4783\n",
      "Epoch 389/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0356 - mae: 0.5309 - mse: 0.4727 - val_loss: 0.0173 - val_mae: 0.5244 - val_mse: 0.4614\n",
      "Epoch 390/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0354 - mae: 0.5285 - mse: 0.4668 - val_loss: 0.0173 - val_mae: 0.5238 - val_mse: 0.4599\n",
      "Epoch 391/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0355 - mae: 0.5292 - mse: 0.4676 - val_loss: 0.0176 - val_mae: 0.5324 - val_mse: 0.4779\n",
      "Epoch 392/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0355 - mae: 0.5305 - mse: 0.4745 - val_loss: 0.0174 - val_mae: 0.5263 - val_mse: 0.4597\n",
      "Epoch 393/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0359 - mae: 0.5356 - mse: 0.4751 - val_loss: 0.0185 - val_mae: 0.5605 - val_mse: 0.5273\n",
      "Epoch 394/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0369 - mae: 0.5506 - mse: 0.5097 - val_loss: 0.0179 - val_mae: 0.5431 - val_mse: 0.4815\n",
      "Epoch 395/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0375 - mae: 0.5597 - mse: 0.5127 - val_loss: 0.0193 - val_mae: 0.5834 - val_mse: 0.5673\n",
      "Epoch 396/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0383 - mae: 0.5713 - mse: 0.5481 - val_loss: 0.0175 - val_mae: 0.5307 - val_mse: 0.4637\n",
      "Epoch 397/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0364 - mae: 0.5437 - mse: 0.4861 - val_loss: 0.0174 - val_mae: 0.5272 - val_mse: 0.4674\n",
      "Epoch 398/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0354 - mae: 0.5285 - mse: 0.4690 - val_loss: 0.0180 - val_mae: 0.5454 - val_mse: 0.5014\n",
      "Epoch 399/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0362 - mae: 0.5404 - mse: 0.4916 - val_loss: 0.0176 - val_mae: 0.5328 - val_mse: 0.4658\n",
      "Epoch 400/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0367 - mae: 0.5471 - mse: 0.4894 - val_loss: 0.0177 - val_mae: 0.5358 - val_mse: 0.4845\n",
      "Epoch 401/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0359 - mae: 0.5351 - mse: 0.4815 - val_loss: 0.0175 - val_mae: 0.5305 - val_mse: 0.4751\n",
      "Epoch 402/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0355 - mae: 0.5301 - mse: 0.4700 - val_loss: 0.0174 - val_mae: 0.5279 - val_mse: 0.4623\n",
      "Epoch 403/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0361 - mae: 0.5385 - mse: 0.4794 - val_loss: 0.0181 - val_mae: 0.5499 - val_mse: 0.5100\n",
      "Epoch 404/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0363 - mae: 0.5411 - mse: 0.4945 - val_loss: 0.0173 - val_mae: 0.5242 - val_mse: 0.4597\n",
      "Epoch 405/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0355 - mae: 0.5304 - mse: 0.4685 - val_loss: 0.0173 - val_mae: 0.5241 - val_mse: 0.4624\n",
      "Epoch 406/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0353 - mae: 0.5267 - mse: 0.4648 - val_loss: 0.0178 - val_mae: 0.5406 - val_mse: 0.4937\n",
      "Epoch 407/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0358 - mae: 0.5343 - mse: 0.4813 - val_loss: 0.0174 - val_mae: 0.5273 - val_mse: 0.4614\n",
      "Epoch 408/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0361 - mae: 0.5392 - mse: 0.4810 - val_loss: 0.0180 - val_mae: 0.5452 - val_mse: 0.5014\n",
      "Epoch 409/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0360 - mae: 0.5378 - mse: 0.4877 - val_loss: 0.0173 - val_mae: 0.5231 - val_mse: 0.4564\n",
      "Epoch 410/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0357 - mae: 0.5331 - mse: 0.4709 - val_loss: 0.0173 - val_mae: 0.5250 - val_mse: 0.4636\n",
      "Epoch 411/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0354 - mae: 0.5282 - mse: 0.4693 - val_loss: 0.0174 - val_mae: 0.5280 - val_mse: 0.4698\n",
      "Epoch 412/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0353 - mae: 0.5272 - mse: 0.4664 - val_loss: 0.0172 - val_mae: 0.5225 - val_mse: 0.4553\n",
      "Epoch 413/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0355 - mae: 0.5300 - mse: 0.4667 - val_loss: 0.0178 - val_mae: 0.5384 - val_mse: 0.4890\n",
      "Epoch 414/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0358 - mae: 0.5338 - mse: 0.4800 - val_loss: 0.0174 - val_mae: 0.5263 - val_mse: 0.4591\n",
      "Epoch 415/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0359 - mae: 0.5361 - mse: 0.4761 - val_loss: 0.0182 - val_mae: 0.5529 - val_mse: 0.5142\n",
      "Epoch 416/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0364 - mae: 0.5433 - mse: 0.4977 - val_loss: 0.0174 - val_mae: 0.5278 - val_mse: 0.4609\n",
      "Epoch 417/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0362 - mae: 0.5399 - mse: 0.4815 - val_loss: 0.0179 - val_mae: 0.5438 - val_mse: 0.4984\n",
      "Epoch 418/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0360 - mae: 0.5371 - mse: 0.4869 - val_loss: 0.0173 - val_mae: 0.5235 - val_mse: 0.4557\n",
      "Epoch 419/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0357 - mae: 0.5328 - mse: 0.4696 - val_loss: 0.0175 - val_mae: 0.5315 - val_mse: 0.4769\n",
      "Epoch 420/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0354 - mae: 0.5280 - mse: 0.4686 - val_loss: 0.0172 - val_mae: 0.5214 - val_mse: 0.4557\n",
      "Epoch 421/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0354 - mae: 0.5276 - mse: 0.4646 - val_loss: 0.0173 - val_mae: 0.5229 - val_mse: 0.4604\n",
      "Epoch 422/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0351 - mae: 0.5244 - mse: 0.4615 - val_loss: 0.0174 - val_mae: 0.5262 - val_mse: 0.4673\n",
      "Epoch 423/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0351 - mae: 0.5242 - mse: 0.4630 - val_loss: 0.0172 - val_mae: 0.5218 - val_mse: 0.4548\n",
      "Epoch 424/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0354 - mae: 0.5284 - mse: 0.4676 - val_loss: 0.0178 - val_mae: 0.5403 - val_mse: 0.4930\n",
      "Epoch 425/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0358 - mae: 0.5346 - mse: 0.4824 - val_loss: 0.0174 - val_mae: 0.5270 - val_mse: 0.4605\n",
      "Epoch 426/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0360 - mae: 0.5371 - mse: 0.4797 - val_loss: 0.0186 - val_mae: 0.5630 - val_mse: 0.5321\n",
      "Epoch 427/2000\n",
      "1/1 [==============================] - 23s 23s/step - loss: 0.0369 - mae: 0.5504 - mse: 0.5097 - val_loss: 0.0177 - val_mae: 0.5357 - val_mse: 0.4697\n",
      "Epoch 428/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0369 - mae: 0.5511 - mse: 0.4974 - val_loss: 0.0182 - val_mae: 0.5522 - val_mse: 0.5138\n",
      "Epoch 429/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0364 - mae: 0.5435 - mse: 0.4984 - val_loss: 0.0173 - val_mae: 0.5229 - val_mse: 0.4574\n",
      "Epoch 430/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0353 - mae: 0.5269 - mse: 0.4633 - val_loss: 0.0173 - val_mae: 0.5252 - val_mse: 0.4564\n",
      "Epoch 431/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0357 - mae: 0.5334 - mse: 0.4706 - val_loss: 0.0182 - val_mae: 0.5527 - val_mse: 0.5149\n",
      "Epoch 432/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0365 - mae: 0.5445 - mse: 0.4993 - val_loss: 0.0173 - val_mae: 0.5237 - val_mse: 0.4555\n",
      "Epoch 433/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0357 - mae: 0.5331 - mse: 0.4674 - val_loss: 0.0172 - val_mae: 0.5225 - val_mse: 0.4595\n",
      "Epoch 434/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0352 - mae: 0.5253 - mse: 0.4617 - val_loss: 0.0177 - val_mae: 0.5362 - val_mse: 0.4865\n",
      "Epoch 435/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0354 - mae: 0.5290 - mse: 0.4722 - val_loss: 0.0174 - val_mae: 0.5279 - val_mse: 0.4622\n",
      "Epoch 436/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0361 - mae: 0.5390 - mse: 0.4825 - val_loss: 0.0182 - val_mae: 0.5515 - val_mse: 0.5126\n",
      "Epoch 437/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0362 - mae: 0.5405 - mse: 0.4912 - val_loss: 0.0173 - val_mae: 0.5255 - val_mse: 0.4587\n",
      "Epoch 438/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0359 - mae: 0.5358 - mse: 0.4771 - val_loss: 0.0174 - val_mae: 0.5283 - val_mse: 0.4717\n",
      "Epoch 439/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0353 - mae: 0.5271 - mse: 0.4659 - val_loss: 0.0173 - val_mae: 0.5238 - val_mse: 0.4624\n",
      "Epoch 440/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0351 - mae: 0.5244 - mse: 0.4623 - val_loss: 0.0172 - val_mae: 0.5223 - val_mse: 0.4536\n",
      "Epoch 441/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0356 - mae: 0.5316 - mse: 0.4676 - val_loss: 0.0178 - val_mae: 0.5408 - val_mse: 0.4934\n",
      "Epoch 442/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0357 - mae: 0.5331 - mse: 0.4804 - val_loss: 0.0172 - val_mae: 0.5224 - val_mse: 0.4534\n",
      "Epoch 443/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0354 - mae: 0.5290 - mse: 0.4644 - val_loss: 0.0173 - val_mae: 0.5254 - val_mse: 0.4654\n",
      "Epoch 444/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0351 - mae: 0.5236 - mse: 0.4620 - val_loss: 0.0173 - val_mae: 0.5231 - val_mse: 0.4613\n",
      "Epoch 445/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0350 - mae: 0.5217 - mse: 0.4588 - val_loss: 0.0172 - val_mae: 0.5214 - val_mse: 0.4531\n",
      "Epoch 446/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0354 - mae: 0.5287 - mse: 0.4661 - val_loss: 0.0182 - val_mae: 0.5514 - val_mse: 0.5118\n",
      "Epoch 447/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0363 - mae: 0.5416 - mse: 0.4968 - val_loss: 0.0178 - val_mae: 0.5379 - val_mse: 0.4742\n",
      "Epoch 448/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0370 - mae: 0.5526 - mse: 0.5012 - val_loss: 0.0188 - val_mae: 0.5699 - val_mse: 0.5443\n",
      "Epoch 449/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0373 - mae: 0.5565 - mse: 0.5224 - val_loss: 0.0173 - val_mae: 0.5254 - val_mse: 0.4555\n",
      "Epoch 450/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0357 - mae: 0.5325 - mse: 0.4666 - val_loss: 0.0172 - val_mae: 0.5217 - val_mse: 0.4556\n",
      "Epoch 451/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0352 - mae: 0.5251 - mse: 0.4579 - val_loss: 0.0180 - val_mae: 0.5468 - val_mse: 0.5042\n",
      "Epoch 452/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0362 - mae: 0.5398 - mse: 0.4908 - val_loss: 0.0174 - val_mae: 0.5260 - val_mse: 0.4562\n",
      "Epoch 453/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0358 - mae: 0.5350 - mse: 0.4715 - val_loss: 0.0173 - val_mae: 0.5247 - val_mse: 0.4642\n",
      "Epoch 454/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0351 - mae: 0.5236 - mse: 0.4608 - val_loss: 0.0175 - val_mae: 0.5293 - val_mse: 0.4737\n",
      "Epoch 455/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0352 - mae: 0.5259 - mse: 0.4673 - val_loss: 0.0173 - val_mae: 0.5242 - val_mse: 0.4564\n",
      "Epoch 456/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0359 - mae: 0.5355 - mse: 0.4747 - val_loss: 0.0179 - val_mae: 0.5413 - val_mse: 0.4950\n",
      "Epoch 457/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0357 - mae: 0.5322 - mse: 0.4795 - val_loss: 0.0172 - val_mae: 0.5207 - val_mse: 0.4536\n",
      "Epoch 458/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0352 - mae: 0.5257 - mse: 0.4637 - val_loss: 0.0172 - val_mae: 0.5224 - val_mse: 0.4603\n",
      "Epoch 459/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0351 - mae: 0.5234 - mse: 0.4614 - val_loss: 0.0173 - val_mae: 0.5235 - val_mse: 0.4621\n",
      "Epoch 460/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0350 - mae: 0.5228 - mse: 0.4601 - val_loss: 0.0171 - val_mae: 0.5194 - val_mse: 0.4506\n",
      "Epoch 461/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0351 - mae: 0.5234 - mse: 0.4574 - val_loss: 0.0175 - val_mae: 0.5314 - val_mse: 0.4760\n",
      "Epoch 462/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0352 - mae: 0.5260 - mse: 0.4662 - val_loss: 0.0172 - val_mae: 0.5202 - val_mse: 0.4498\n",
      "Epoch 463/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0351 - mae: 0.5242 - mse: 0.4554 - val_loss: 0.0175 - val_mae: 0.5306 - val_mse: 0.4746\n",
      "Epoch 464/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0352 - mae: 0.5252 - mse: 0.4650 - val_loss: 0.0171 - val_mae: 0.5194 - val_mse: 0.4491\n",
      "Epoch 465/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0351 - mae: 0.5244 - mse: 0.4590 - val_loss: 0.0174 - val_mae: 0.5267 - val_mse: 0.4679\n",
      "Epoch 466/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0353 - mae: 0.5264 - mse: 0.4653 - val_loss: 0.0171 - val_mae: 0.5184 - val_mse: 0.4504\n",
      "Epoch 467/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0350 - mae: 0.5217 - mse: 0.4580 - val_loss: 0.0171 - val_mae: 0.5197 - val_mse: 0.4551\n",
      "Epoch 468/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0348 - mae: 0.5197 - mse: 0.4552 - val_loss: 0.0172 - val_mae: 0.5202 - val_mse: 0.4566\n",
      "Epoch 469/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0349 - mae: 0.5213 - mse: 0.4565 - val_loss: 0.0172 - val_mae: 0.5200 - val_mse: 0.4564\n",
      "Epoch 470/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0349 - mae: 0.5202 - mse: 0.4566 - val_loss: 0.0171 - val_mae: 0.5182 - val_mse: 0.4510\n",
      "Epoch 471/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0349 - mae: 0.5207 - mse: 0.4558 - val_loss: 0.0174 - val_mae: 0.5283 - val_mse: 0.4725\n",
      "Epoch 472/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0351 - mae: 0.5239 - mse: 0.4636 - val_loss: 0.0174 - val_mae: 0.5269 - val_mse: 0.4581\n",
      "Epoch 473/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0359 - mae: 0.5358 - mse: 0.4762 - val_loss: 0.0194 - val_mae: 0.5864 - val_mse: 0.5748\n",
      "Epoch 474/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0383 - mae: 0.5715 - mse: 0.5500 - val_loss: 0.0186 - val_mae: 0.5649 - val_mse: 0.5086\n",
      "Epoch 475/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0391 - mae: 0.5841 - mse: 0.5496 - val_loss: 0.0187 - val_mae: 0.5679 - val_mse: 0.5424\n",
      "Epoch 476/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0372 - mae: 0.5560 - mse: 0.5220 - val_loss: 0.0174 - val_mae: 0.5279 - val_mse: 0.4668\n",
      "Epoch 477/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0354 - mae: 0.5282 - mse: 0.4656 - val_loss: 0.0178 - val_mae: 0.5400 - val_mse: 0.4695\n",
      "Epoch 478/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0371 - mae: 0.5539 - mse: 0.4936 - val_loss: 0.0181 - val_mae: 0.5490 - val_mse: 0.5078\n",
      "Epoch 479/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0363 - mae: 0.5413 - mse: 0.4934 - val_loss: 0.0175 - val_mae: 0.5313 - val_mse: 0.4757\n",
      "Epoch 480/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0354 - mae: 0.5287 - mse: 0.4686 - val_loss: 0.0178 - val_mae: 0.5406 - val_mse: 0.4751\n",
      "Epoch 481/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0371 - mae: 0.5545 - mse: 0.5018 - val_loss: 0.0184 - val_mae: 0.5562 - val_mse: 0.5204\n",
      "Epoch 482/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0366 - mae: 0.5456 - mse: 0.5004 - val_loss: 0.0173 - val_mae: 0.5240 - val_mse: 0.4632\n",
      "Epoch 483/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0350 - mae: 0.5224 - mse: 0.4584 - val_loss: 0.0176 - val_mae: 0.5346 - val_mse: 0.4703\n",
      "Epoch 484/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0365 - mae: 0.5453 - mse: 0.4916 - val_loss: 0.0188 - val_mae: 0.5683 - val_mse: 0.5408\n",
      "Epoch 485/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0373 - mae: 0.5565 - mse: 0.5197 - val_loss: 0.0172 - val_mae: 0.5204 - val_mse: 0.4522\n",
      "Epoch 486/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0351 - mae: 0.5241 - mse: 0.4558 - val_loss: 0.0174 - val_mae: 0.5270 - val_mse: 0.4563\n",
      "Epoch 487/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0360 - mae: 0.5366 - mse: 0.4729 - val_loss: 0.0187 - val_mae: 0.5672 - val_mse: 0.5393\n",
      "Epoch 488/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0373 - mae: 0.5562 - mse: 0.5199 - val_loss: 0.0172 - val_mae: 0.5220 - val_mse: 0.4518\n",
      "Epoch 489/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0353 - mae: 0.5273 - mse: 0.4598 - val_loss: 0.0173 - val_mae: 0.5246 - val_mse: 0.4535\n",
      "Epoch 490/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0357 - mae: 0.5331 - mse: 0.4671 - val_loss: 0.0183 - val_mae: 0.5537 - val_mse: 0.5154\n",
      "Epoch 491/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0365 - mae: 0.5442 - mse: 0.4981 - val_loss: 0.0172 - val_mae: 0.5197 - val_mse: 0.4510\n",
      "Epoch 492/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0349 - mae: 0.5210 - mse: 0.4520 - val_loss: 0.0173 - val_mae: 0.5235 - val_mse: 0.4534\n",
      "Epoch 493/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0356 - mae: 0.5313 - mse: 0.4686 - val_loss: 0.0183 - val_mae: 0.5532 - val_mse: 0.5142\n",
      "Epoch 494/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0365 - mae: 0.5448 - mse: 0.4975 - val_loss: 0.0172 - val_mae: 0.5207 - val_mse: 0.4514\n",
      "Epoch 495/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0353 - mae: 0.5267 - mse: 0.4626 - val_loss: 0.0171 - val_mae: 0.5190 - val_mse: 0.4512\n",
      "Epoch 496/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0350 - mae: 0.5218 - mse: 0.4568 - val_loss: 0.0178 - val_mae: 0.5388 - val_mse: 0.4894\n",
      "Epoch 497/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0357 - mae: 0.5326 - mse: 0.4766 - val_loss: 0.0172 - val_mae: 0.5223 - val_mse: 0.4515\n",
      "Epoch 498/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0355 - mae: 0.5298 - mse: 0.4650 - val_loss: 0.0174 - val_mae: 0.5262 - val_mse: 0.4663\n",
      "Epoch 499/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0351 - mae: 0.5237 - mse: 0.4592 - val_loss: 0.0172 - val_mae: 0.5224 - val_mse: 0.4587\n",
      "Epoch 500/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0350 - mae: 0.5220 - mse: 0.4571 - val_loss: 0.0171 - val_mae: 0.5196 - val_mse: 0.4481\n",
      "Epoch 501/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0351 - mae: 0.5240 - mse: 0.4560 - val_loss: 0.0175 - val_mae: 0.5288 - val_mse: 0.4714\n",
      "Epoch 502/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0352 - mae: 0.5253 - mse: 0.4655 - val_loss: 0.0171 - val_mae: 0.5180 - val_mse: 0.4489\n",
      "Epoch 503/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0349 - mae: 0.5216 - mse: 0.4552 - val_loss: 0.0171 - val_mae: 0.5184 - val_mse: 0.4510\n",
      "Epoch 504/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0347 - mae: 0.5172 - mse: 0.4504 - val_loss: 0.0173 - val_mae: 0.5246 - val_mse: 0.4645\n",
      "Epoch 505/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0350 - mae: 0.5223 - mse: 0.4594 - val_loss: 0.0171 - val_mae: 0.5189 - val_mse: 0.4499\n",
      "Epoch 506/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0351 - mae: 0.5232 - mse: 0.4581 - val_loss: 0.0174 - val_mae: 0.5267 - val_mse: 0.4685\n",
      "Epoch 507/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0351 - mae: 0.5234 - mse: 0.4613 - val_loss: 0.0171 - val_mae: 0.5178 - val_mse: 0.4485\n",
      "Epoch 508/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0349 - mae: 0.5210 - mse: 0.4554 - val_loss: 0.0172 - val_mae: 0.5225 - val_mse: 0.4604\n",
      "Epoch 509/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0349 - mae: 0.5211 - mse: 0.4576 - val_loss: 0.0171 - val_mae: 0.5176 - val_mse: 0.4495\n",
      "Epoch 510/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0347 - mae: 0.5183 - mse: 0.4507 - val_loss: 0.0171 - val_mae: 0.5179 - val_mse: 0.4503\n",
      "Epoch 511/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0348 - mae: 0.5200 - mse: 0.4528 - val_loss: 0.0171 - val_mae: 0.5196 - val_mse: 0.4545\n",
      "Epoch 512/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0347 - mae: 0.5180 - mse: 0.4506 - val_loss: 0.0171 - val_mae: 0.5175 - val_mse: 0.4497\n",
      "Epoch 513/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0347 - mae: 0.5175 - mse: 0.4497 - val_loss: 0.0172 - val_mae: 0.5200 - val_mse: 0.4559\n",
      "Epoch 514/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0347 - mae: 0.5179 - mse: 0.4515 - val_loss: 0.0171 - val_mae: 0.5172 - val_mse: 0.4472\n",
      "Epoch 515/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0348 - mae: 0.5199 - mse: 0.4517 - val_loss: 0.0174 - val_mae: 0.5283 - val_mse: 0.4719\n",
      "Epoch 516/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0351 - mae: 0.5233 - mse: 0.4642 - val_loss: 0.0173 - val_mae: 0.5252 - val_mse: 0.4558\n",
      "Epoch 517/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0358 - mae: 0.5336 - mse: 0.4720 - val_loss: 0.0191 - val_mae: 0.5791 - val_mse: 0.5607\n",
      "Epoch 518/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0378 - mae: 0.5649 - mse: 0.5369 - val_loss: 0.0180 - val_mae: 0.5469 - val_mse: 0.4814\n",
      "Epoch 519/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0376 - mae: 0.5615 - mse: 0.5108 - val_loss: 0.0177 - val_mae: 0.5373 - val_mse: 0.4870\n",
      "Epoch 520/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0355 - mae: 0.5300 - mse: 0.4737 - val_loss: 0.0177 - val_mae: 0.5362 - val_mse: 0.4842\n",
      "Epoch 521/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0357 - mae: 0.5321 - mse: 0.4746 - val_loss: 0.0177 - val_mae: 0.5355 - val_mse: 0.4631\n",
      "Epoch 522/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0367 - mae: 0.5470 - mse: 0.4844 - val_loss: 0.0175 - val_mae: 0.5290 - val_mse: 0.4708\n",
      "Epoch 523/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0353 - mae: 0.5266 - mse: 0.4642 - val_loss: 0.0178 - val_mae: 0.5381 - val_mse: 0.4885\n",
      "Epoch 524/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0355 - mae: 0.5302 - mse: 0.4742 - val_loss: 0.0175 - val_mae: 0.5317 - val_mse: 0.4631\n",
      "Epoch 525/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0364 - mae: 0.5430 - mse: 0.4819 - val_loss: 0.0176 - val_mae: 0.5331 - val_mse: 0.4801\n",
      "Epoch 526/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0353 - mae: 0.5268 - mse: 0.4679 - val_loss: 0.0174 - val_mae: 0.5271 - val_mse: 0.4694\n",
      "Epoch 527/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0350 - mae: 0.5229 - mse: 0.4606 - val_loss: 0.0175 - val_mae: 0.5311 - val_mse: 0.4655\n",
      "Epoch 528/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0362 - mae: 0.5410 - mse: 0.4858 - val_loss: 0.0184 - val_mae: 0.5584 - val_mse: 0.5233\n",
      "Epoch 529/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0366 - mae: 0.5464 - mse: 0.5014 - val_loss: 0.0171 - val_mae: 0.5179 - val_mse: 0.4479\n",
      "Epoch 530/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0350 - mae: 0.5218 - mse: 0.4526 - val_loss: 0.0172 - val_mae: 0.5211 - val_mse: 0.4485\n",
      "Epoch 531/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0353 - mae: 0.5275 - mse: 0.4578 - val_loss: 0.0180 - val_mae: 0.5446 - val_mse: 0.4989\n",
      "Epoch 532/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0359 - mae: 0.5361 - mse: 0.4842 - val_loss: 0.0171 - val_mae: 0.5191 - val_mse: 0.4478\n",
      "Epoch 533/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0350 - mae: 0.5224 - mse: 0.4537 - val_loss: 0.0172 - val_mae: 0.5205 - val_mse: 0.4471\n",
      "Epoch 534/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0354 - mae: 0.5290 - mse: 0.4617 - val_loss: 0.0179 - val_mae: 0.5437 - val_mse: 0.4972\n",
      "Epoch 535/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0358 - mae: 0.5349 - mse: 0.4818 - val_loss: 0.0171 - val_mae: 0.5172 - val_mse: 0.4456\n",
      "Epoch 536/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0349 - mae: 0.5215 - mse: 0.4530 - val_loss: 0.0171 - val_mae: 0.5172 - val_mse: 0.4465\n",
      "Epoch 537/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0349 - mae: 0.5208 - mse: 0.4545 - val_loss: 0.0180 - val_mae: 0.5459 - val_mse: 0.5015\n",
      "Epoch 538/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0358 - mae: 0.5348 - mse: 0.4832 - val_loss: 0.0175 - val_mae: 0.5318 - val_mse: 0.4655\n",
      "Epoch 539/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0363 - mae: 0.5421 - mse: 0.4873 - val_loss: 0.0180 - val_mae: 0.5468 - val_mse: 0.5032\n",
      "Epoch 540/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0359 - mae: 0.5360 - mse: 0.4844 - val_loss: 0.0171 - val_mae: 0.5168 - val_mse: 0.4463\n",
      "Epoch 541/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0348 - mae: 0.5200 - mse: 0.4499 - val_loss: 0.0171 - val_mae: 0.5186 - val_mse: 0.4455\n",
      "Epoch 542/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0351 - mae: 0.5243 - mse: 0.4546 - val_loss: 0.0179 - val_mae: 0.5418 - val_mse: 0.4943\n",
      "Epoch 543/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0356 - mae: 0.5312 - mse: 0.4761 - val_loss: 0.0171 - val_mae: 0.5174 - val_mse: 0.4460\n",
      "Epoch 544/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0347 - mae: 0.5185 - mse: 0.4466 - val_loss: 0.0171 - val_mae: 0.5182 - val_mse: 0.4454\n",
      "Epoch 545/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0350 - mae: 0.5227 - mse: 0.4542 - val_loss: 0.0179 - val_mae: 0.5424 - val_mse: 0.4955\n",
      "Epoch 546/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0357 - mae: 0.5330 - mse: 0.4786 - val_loss: 0.0171 - val_mae: 0.5174 - val_mse: 0.4461\n",
      "Epoch 547/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0350 - mae: 0.5229 - mse: 0.4564 - val_loss: 0.0171 - val_mae: 0.5167 - val_mse: 0.4476\n",
      "Epoch 548/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0347 - mae: 0.5182 - mse: 0.4498 - val_loss: 0.0175 - val_mae: 0.5315 - val_mse: 0.4767\n",
      "Epoch 549/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0351 - mae: 0.5245 - mse: 0.4636 - val_loss: 0.0172 - val_mae: 0.5199 - val_mse: 0.4486\n",
      "Epoch 550/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0353 - mae: 0.5262 - mse: 0.4604 - val_loss: 0.0174 - val_mae: 0.5269 - val_mse: 0.4681\n",
      "Epoch 551/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0350 - mae: 0.5225 - mse: 0.4600 - val_loss: 0.0170 - val_mae: 0.5162 - val_mse: 0.4462\n",
      "Epoch 552/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0346 - mae: 0.5170 - mse: 0.4481 - val_loss: 0.0170 - val_mae: 0.5158 - val_mse: 0.4433\n",
      "Epoch 553/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0349 - mae: 0.5203 - mse: 0.4511 - val_loss: 0.0174 - val_mae: 0.5283 - val_mse: 0.4703\n",
      "Epoch 554/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0350 - mae: 0.5224 - mse: 0.4590 - val_loss: 0.0171 - val_mae: 0.5170 - val_mse: 0.4437\n",
      "Epoch 555/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0350 - mae: 0.5220 - mse: 0.4517 - val_loss: 0.0172 - val_mae: 0.5206 - val_mse: 0.4565\n",
      "Epoch 556/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0346 - mae: 0.5167 - mse: 0.4491 - val_loss: 0.0170 - val_mae: 0.5164 - val_mse: 0.4480\n",
      "Epoch 557/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0345 - mae: 0.5157 - mse: 0.4462 - val_loss: 0.0170 - val_mae: 0.5161 - val_mse: 0.4443\n",
      "Epoch 558/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0348 - mae: 0.5193 - mse: 0.4508 - val_loss: 0.0174 - val_mae: 0.5285 - val_mse: 0.4718\n",
      "Epoch 559/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0350 - mae: 0.5221 - mse: 0.4593 - val_loss: 0.0171 - val_mae: 0.5194 - val_mse: 0.4475\n",
      "Epoch 560/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0351 - mae: 0.5240 - mse: 0.4576 - val_loss: 0.0175 - val_mae: 0.5314 - val_mse: 0.4770\n",
      "Epoch 561/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0351 - mae: 0.5240 - mse: 0.4653 - val_loss: 0.0171 - val_mae: 0.5176 - val_mse: 0.4440\n",
      "Epoch 562/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0350 - mae: 0.5220 - mse: 0.4539 - val_loss: 0.0173 - val_mae: 0.5233 - val_mse: 0.4619\n",
      "Epoch 563/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0348 - mae: 0.5199 - mse: 0.4554 - val_loss: 0.0170 - val_mae: 0.5159 - val_mse: 0.4463\n",
      "Epoch 564/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0346 - mae: 0.5162 - mse: 0.4468 - val_loss: 0.0170 - val_mae: 0.5150 - val_mse: 0.4421\n",
      "Epoch 565/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0347 - mae: 0.5184 - mse: 0.4473 - val_loss: 0.0173 - val_mae: 0.5253 - val_mse: 0.4660\n",
      "Epoch 566/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0349 - mae: 0.5205 - mse: 0.4572 - val_loss: 0.0170 - val_mae: 0.5161 - val_mse: 0.4434\n",
      "Epoch 567/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0348 - mae: 0.5201 - mse: 0.4516 - val_loss: 0.0174 - val_mae: 0.5265 - val_mse: 0.4687\n",
      "Epoch 568/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0348 - mae: 0.5193 - mse: 0.4563 - val_loss: 0.0171 - val_mae: 0.5167 - val_mse: 0.4446\n",
      "Epoch 569/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0350 - mae: 0.5221 - mse: 0.4540 - val_loss: 0.0173 - val_mae: 0.5250 - val_mse: 0.4660\n",
      "Epoch 570/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0348 - mae: 0.5199 - mse: 0.4567 - val_loss: 0.0170 - val_mae: 0.5154 - val_mse: 0.4428\n",
      "Epoch 571/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0346 - mae: 0.5170 - mse: 0.4479 - val_loss: 0.0171 - val_mae: 0.5192 - val_mse: 0.4546\n",
      "Epoch 572/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0346 - mae: 0.5163 - mse: 0.4481 - val_loss: 0.0170 - val_mae: 0.5151 - val_mse: 0.4453\n",
      "Epoch 573/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0344 - mae: 0.5130 - mse: 0.4426 - val_loss: 0.0170 - val_mae: 0.5142 - val_mse: 0.4425\n",
      "Epoch 574/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0345 - mae: 0.5148 - mse: 0.4440 - val_loss: 0.0171 - val_mae: 0.5177 - val_mse: 0.4515\n",
      "Epoch 575/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0345 - mae: 0.5151 - mse: 0.4474 - val_loss: 0.0170 - val_mae: 0.5146 - val_mse: 0.4417\n",
      "Epoch 576/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0345 - mae: 0.5154 - mse: 0.4453 - val_loss: 0.0173 - val_mae: 0.5239 - val_mse: 0.4635\n",
      "Epoch 577/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0347 - mae: 0.5179 - mse: 0.4542 - val_loss: 0.0171 - val_mae: 0.5174 - val_mse: 0.4436\n",
      "Epoch 578/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0350 - mae: 0.5220 - mse: 0.4532 - val_loss: 0.0176 - val_mae: 0.5330 - val_mse: 0.4796\n",
      "Epoch 579/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0351 - mae: 0.5238 - mse: 0.4632 - val_loss: 0.0173 - val_mae: 0.5251 - val_mse: 0.4524\n",
      "Epoch 580/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0357 - mae: 0.5328 - mse: 0.4699 - val_loss: 0.0182 - val_mae: 0.5515 - val_mse: 0.5124\n",
      "Epoch 581/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0363 - mae: 0.5415 - mse: 0.4954 - val_loss: 0.0172 - val_mae: 0.5210 - val_mse: 0.4454\n",
      "Epoch 582/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0354 - mae: 0.5287 - mse: 0.4592 - val_loss: 0.0171 - val_mae: 0.5176 - val_mse: 0.4497\n",
      "Epoch 583/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0345 - mae: 0.5144 - mse: 0.4446 - val_loss: 0.0175 - val_mae: 0.5289 - val_mse: 0.4719\n",
      "Epoch 584/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0351 - mae: 0.5238 - mse: 0.4624 - val_loss: 0.0172 - val_mae: 0.5227 - val_mse: 0.4499\n",
      "Epoch 585/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0354 - mae: 0.5287 - mse: 0.4622 - val_loss: 0.0175 - val_mae: 0.5313 - val_mse: 0.4769\n",
      "Epoch 586/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0351 - mae: 0.5236 - mse: 0.4642 - val_loss: 0.0170 - val_mae: 0.5148 - val_mse: 0.4455\n",
      "Epoch 587/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0344 - mae: 0.5141 - mse: 0.4435 - val_loss: 0.0170 - val_mae: 0.5162 - val_mse: 0.4442\n",
      "Epoch 588/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0349 - mae: 0.5206 - mse: 0.4514 - val_loss: 0.0178 - val_mae: 0.5385 - val_mse: 0.4889\n",
      "Epoch 589/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0354 - mae: 0.5282 - mse: 0.4712 - val_loss: 0.0171 - val_mae: 0.5187 - val_mse: 0.4441\n",
      "Epoch 590/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0351 - mae: 0.5234 - mse: 0.4539 - val_loss: 0.0171 - val_mae: 0.5169 - val_mse: 0.4484\n",
      "Epoch 591/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0345 - mae: 0.5143 - mse: 0.4450 - val_loss: 0.0173 - val_mae: 0.5236 - val_mse: 0.4615\n",
      "Epoch 592/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0347 - mae: 0.5182 - mse: 0.4530 - val_loss: 0.0171 - val_mae: 0.5191 - val_mse: 0.4431\n",
      "Epoch 593/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0351 - mae: 0.5245 - mse: 0.4548 - val_loss: 0.0174 - val_mae: 0.5274 - val_mse: 0.4689\n",
      "Epoch 594/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0350 - mae: 0.5223 - mse: 0.4606 - val_loss: 0.0169 - val_mae: 0.5135 - val_mse: 0.4396\n",
      "Epoch 595/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0345 - mae: 0.5151 - mse: 0.4427 - val_loss: 0.0169 - val_mae: 0.5135 - val_mse: 0.4410\n",
      "Epoch 596/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0343 - mae: 0.5121 - mse: 0.4420 - val_loss: 0.0174 - val_mae: 0.5271 - val_mse: 0.4693\n",
      "Epoch 597/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0349 - mae: 0.5215 - mse: 0.4598 - val_loss: 0.0174 - val_mae: 0.5286 - val_mse: 0.4598\n",
      "Epoch 598/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0358 - mae: 0.5345 - mse: 0.4758 - val_loss: 0.0190 - val_mae: 0.5746 - val_mse: 0.5528\n",
      "Epoch 599/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0376 - mae: 0.5605 - mse: 0.5297 - val_loss: 0.0176 - val_mae: 0.5340 - val_mse: 0.4601\n",
      "Epoch 600/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0364 - mae: 0.5427 - mse: 0.4774 - val_loss: 0.0171 - val_mae: 0.5186 - val_mse: 0.4487\n",
      "Epoch 601/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0348 - mae: 0.5193 - mse: 0.4485 - val_loss: 0.0181 - val_mae: 0.5491 - val_mse: 0.5073\n",
      "Epoch 602/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0360 - mae: 0.5374 - mse: 0.4875 - val_loss: 0.0172 - val_mae: 0.5202 - val_mse: 0.4444\n",
      "Epoch 603/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0353 - mae: 0.5262 - mse: 0.4549 - val_loss: 0.0170 - val_mae: 0.5161 - val_mse: 0.4422\n",
      "Epoch 604/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0348 - mae: 0.5194 - mse: 0.4467 - val_loss: 0.0179 - val_mae: 0.5435 - val_mse: 0.4973\n",
      "Epoch 605/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0357 - mae: 0.5333 - mse: 0.4788 - val_loss: 0.0172 - val_mae: 0.5204 - val_mse: 0.4509\n",
      "Epoch 606/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0350 - mae: 0.5227 - mse: 0.4559 - val_loss: 0.0171 - val_mae: 0.5180 - val_mse: 0.4516\n",
      "Epoch 607/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0345 - mae: 0.5150 - mse: 0.4455 - val_loss: 0.0173 - val_mae: 0.5248 - val_mse: 0.4643\n",
      "Epoch 608/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0348 - mae: 0.5197 - mse: 0.4545 - val_loss: 0.0171 - val_mae: 0.5178 - val_mse: 0.4437\n",
      "Epoch 609/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0350 - mae: 0.5218 - mse: 0.4522 - val_loss: 0.0173 - val_mae: 0.5237 - val_mse: 0.4610\n",
      "Epoch 610/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0348 - mae: 0.5195 - mse: 0.4522 - val_loss: 0.0170 - val_mae: 0.5145 - val_mse: 0.4411\n",
      "Epoch 611/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0345 - mae: 0.5150 - mse: 0.4424 - val_loss: 0.0170 - val_mae: 0.5145 - val_mse: 0.4380\n",
      "Epoch 612/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0347 - mae: 0.5174 - mse: 0.4434 - val_loss: 0.0174 - val_mae: 0.5276 - val_mse: 0.4686\n",
      "Epoch 613/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0348 - mae: 0.5199 - mse: 0.4561 - val_loss: 0.0171 - val_mae: 0.5171 - val_mse: 0.4419\n",
      "Epoch 614/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0349 - mae: 0.5206 - mse: 0.4493 - val_loss: 0.0172 - val_mae: 0.5221 - val_mse: 0.4596\n",
      "Epoch 615/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0346 - mae: 0.5170 - mse: 0.4520 - val_loss: 0.0169 - val_mae: 0.5132 - val_mse: 0.4393\n",
      "Epoch 616/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0343 - mae: 0.5116 - mse: 0.4400 - val_loss: 0.0170 - val_mae: 0.5141 - val_mse: 0.4443\n",
      "Epoch 617/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0343 - mae: 0.5122 - mse: 0.4426 - val_loss: 0.0169 - val_mae: 0.5133 - val_mse: 0.4426\n",
      "Epoch 618/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0344 - mae: 0.5130 - mse: 0.4424 - val_loss: 0.0169 - val_mae: 0.5124 - val_mse: 0.4397\n",
      "Epoch 619/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0342 - mae: 0.5107 - mse: 0.4377 - val_loss: 0.0170 - val_mae: 0.5153 - val_mse: 0.4477\n",
      "Epoch 620/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0343 - mae: 0.5118 - mse: 0.4415 - val_loss: 0.0169 - val_mae: 0.5130 - val_mse: 0.4386\n",
      "Epoch 621/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0345 - mae: 0.5145 - mse: 0.4438 - val_loss: 0.0172 - val_mae: 0.5223 - val_mse: 0.4612\n",
      "Epoch 622/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0347 - mae: 0.5185 - mse: 0.4541 - val_loss: 0.0171 - val_mae: 0.5196 - val_mse: 0.4453\n",
      "Epoch 623/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0352 - mae: 0.5253 - mse: 0.4559 - val_loss: 0.0178 - val_mae: 0.5384 - val_mse: 0.4895\n",
      "Epoch 624/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0356 - mae: 0.5310 - mse: 0.4766 - val_loss: 0.0172 - val_mae: 0.5215 - val_mse: 0.4459\n",
      "Epoch 625/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0353 - mae: 0.5269 - mse: 0.4577 - val_loss: 0.0173 - val_mae: 0.5248 - val_mse: 0.4647\n",
      "Epoch 626/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0348 - mae: 0.5187 - mse: 0.4561 - val_loss: 0.0169 - val_mae: 0.5132 - val_mse: 0.4408\n",
      "Epoch 627/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0343 - mae: 0.5118 - mse: 0.4393 - val_loss: 0.0170 - val_mae: 0.5143 - val_mse: 0.4384\n",
      "Epoch 628/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0346 - mae: 0.5166 - mse: 0.4419 - val_loss: 0.0176 - val_mae: 0.5318 - val_mse: 0.4777\n",
      "Epoch 629/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0352 - mae: 0.5252 - mse: 0.4651 - val_loss: 0.0170 - val_mae: 0.5160 - val_mse: 0.4416\n",
      "Epoch 630/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0347 - mae: 0.5181 - mse: 0.4484 - val_loss: 0.0170 - val_mae: 0.5146 - val_mse: 0.4461\n",
      "Epoch 631/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0342 - mae: 0.5107 - mse: 0.4401 - val_loss: 0.0170 - val_mae: 0.5151 - val_mse: 0.4469\n",
      "Epoch 632/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0344 - mae: 0.5132 - mse: 0.4425 - val_loss: 0.0170 - val_mae: 0.5142 - val_mse: 0.4387\n",
      "Epoch 633/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0345 - mae: 0.5146 - mse: 0.4431 - val_loss: 0.0173 - val_mae: 0.5236 - val_mse: 0.4623\n",
      "Epoch 634/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0347 - mae: 0.5174 - mse: 0.4522 - val_loss: 0.0170 - val_mae: 0.5136 - val_mse: 0.4367\n",
      "Epoch 635/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0345 - mae: 0.5155 - mse: 0.4407 - val_loss: 0.0170 - val_mae: 0.5156 - val_mse: 0.4467\n",
      "Epoch 636/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0343 - mae: 0.5124 - mse: 0.4419 - val_loss: 0.0169 - val_mae: 0.5132 - val_mse: 0.4421\n",
      "Epoch 637/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0342 - mae: 0.5104 - mse: 0.4385 - val_loss: 0.0170 - val_mae: 0.5138 - val_mse: 0.4379\n",
      "Epoch 638/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0345 - mae: 0.5143 - mse: 0.4422 - val_loss: 0.0176 - val_mae: 0.5323 - val_mse: 0.4785\n",
      "Epoch 639/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0350 - mae: 0.5221 - mse: 0.4625 - val_loss: 0.0174 - val_mae: 0.5265 - val_mse: 0.4547\n",
      "Epoch 640/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0357 - mae: 0.5331 - mse: 0.4680 - val_loss: 0.0179 - val_mae: 0.5432 - val_mse: 0.4978\n",
      "Epoch 641/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0358 - mae: 0.5338 - mse: 0.4830 - val_loss: 0.0171 - val_mae: 0.5171 - val_mse: 0.4392\n",
      "Epoch 642/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0349 - mae: 0.5210 - mse: 0.4471 - val_loss: 0.0169 - val_mae: 0.5135 - val_mse: 0.4407\n",
      "Epoch 643/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0343 - mae: 0.5127 - mse: 0.4382 - val_loss: 0.0174 - val_mae: 0.5274 - val_mse: 0.4693\n",
      "Epoch 644/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0349 - mae: 0.5209 - mse: 0.4598 - val_loss: 0.0172 - val_mae: 0.5206 - val_mse: 0.4455\n",
      "Epoch 645/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0352 - mae: 0.5259 - mse: 0.4546 - val_loss: 0.0173 - val_mae: 0.5237 - val_mse: 0.4634\n",
      "Epoch 646/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0346 - mae: 0.5162 - mse: 0.4506 - val_loss: 0.0169 - val_mae: 0.5125 - val_mse: 0.4416\n",
      "Epoch 647/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0343 - mae: 0.5115 - mse: 0.4394 - val_loss: 0.0170 - val_mae: 0.5144 - val_mse: 0.4401\n",
      "Epoch 648/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0345 - mae: 0.5146 - mse: 0.4418 - val_loss: 0.0174 - val_mae: 0.5284 - val_mse: 0.4709\n",
      "Epoch 649/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0350 - mae: 0.5222 - mse: 0.4608 - val_loss: 0.0170 - val_mae: 0.5146 - val_mse: 0.4378\n",
      "Epoch 650/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0346 - mae: 0.5167 - mse: 0.4434 - val_loss: 0.0169 - val_mae: 0.5134 - val_mse: 0.4418\n",
      "Epoch 651/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0342 - mae: 0.5101 - mse: 0.4387 - val_loss: 0.0170 - val_mae: 0.5161 - val_mse: 0.4476\n",
      "Epoch 652/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0343 - mae: 0.5120 - mse: 0.4401 - val_loss: 0.0170 - val_mae: 0.5150 - val_mse: 0.4381\n",
      "Epoch 653/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0346 - mae: 0.5171 - mse: 0.4431 - val_loss: 0.0175 - val_mae: 0.5291 - val_mse: 0.4728\n",
      "Epoch 654/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0349 - mae: 0.5208 - mse: 0.4596 - val_loss: 0.0172 - val_mae: 0.5201 - val_mse: 0.4449\n",
      "Epoch 655/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0350 - mae: 0.5219 - mse: 0.4513 - val_loss: 0.0175 - val_mae: 0.5317 - val_mse: 0.4772\n",
      "Epoch 656/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0350 - mae: 0.5229 - mse: 0.4642 - val_loss: 0.0170 - val_mae: 0.5142 - val_mse: 0.4365\n",
      "Epoch 657/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0346 - mae: 0.5169 - mse: 0.4439 - val_loss: 0.0169 - val_mae: 0.5120 - val_mse: 0.4392\n",
      "Epoch 658/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0342 - mae: 0.5110 - mse: 0.4371 - val_loss: 0.0171 - val_mae: 0.5180 - val_mse: 0.4527\n",
      "Epoch 659/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0344 - mae: 0.5129 - mse: 0.4433 - val_loss: 0.0170 - val_mae: 0.5147 - val_mse: 0.4390\n",
      "Epoch 660/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0346 - mae: 0.5163 - mse: 0.4416 - val_loss: 0.0172 - val_mae: 0.5206 - val_mse: 0.4582\n",
      "Epoch 661/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0345 - mae: 0.5149 - mse: 0.4488 - val_loss: 0.0169 - val_mae: 0.5120 - val_mse: 0.4378\n",
      "Epoch 662/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0342 - mae: 0.5102 - mse: 0.4357 - val_loss: 0.0169 - val_mae: 0.5124 - val_mse: 0.4416\n",
      "Epoch 663/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0340 - mae: 0.5079 - mse: 0.4356 - val_loss: 0.0169 - val_mae: 0.5114 - val_mse: 0.4390\n",
      "Epoch 664/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0342 - mae: 0.5106 - mse: 0.4387 - val_loss: 0.0168 - val_mae: 0.5105 - val_mse: 0.4361\n",
      "Epoch 665/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0341 - mae: 0.5085 - mse: 0.4354 - val_loss: 0.0169 - val_mae: 0.5110 - val_mse: 0.4378\n",
      "Epoch 666/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0340 - mae: 0.5068 - mse: 0.4323 - val_loss: 0.0168 - val_mae: 0.5106 - val_mse: 0.4370\n",
      "Epoch 667/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0340 - mae: 0.5079 - mse: 0.4341 - val_loss: 0.0168 - val_mae: 0.5102 - val_mse: 0.4360\n",
      "Epoch 668/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0339 - mae: 0.5067 - mse: 0.4339 - val_loss: 0.0169 - val_mae: 0.5109 - val_mse: 0.4388\n",
      "Epoch 669/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0339 - mae: 0.5062 - mse: 0.4341 - val_loss: 0.0168 - val_mae: 0.5105 - val_mse: 0.4356\n",
      "Epoch 670/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0340 - mae: 0.5076 - mse: 0.4337 - val_loss: 0.0171 - val_mae: 0.5169 - val_mse: 0.4522\n",
      "Epoch 671/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0343 - mae: 0.5115 - mse: 0.4437 - val_loss: 0.0172 - val_mae: 0.5213 - val_mse: 0.4465\n",
      "Epoch 672/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0351 - mae: 0.5233 - mse: 0.4548 - val_loss: 0.0189 - val_mae: 0.5725 - val_mse: 0.5516\n",
      "Epoch 673/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0378 - mae: 0.5635 - mse: 0.5347 - val_loss: 0.0187 - val_mae: 0.5661 - val_mse: 0.5029\n",
      "Epoch 674/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0387 - mae: 0.5778 - mse: 0.5304 - val_loss: 0.0177 - val_mae: 0.5361 - val_mse: 0.4841\n",
      "Epoch 675/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0354 - mae: 0.5287 - mse: 0.4681 - val_loss: 0.0178 - val_mae: 0.5393 - val_mse: 0.4895\n",
      "Epoch 676/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0356 - mae: 0.5320 - mse: 0.4764 - val_loss: 0.0178 - val_mae: 0.5393 - val_mse: 0.4638\n",
      "Epoch 677/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0368 - mae: 0.5491 - mse: 0.4828 - val_loss: 0.0171 - val_mae: 0.5175 - val_mse: 0.4496\n",
      "Epoch 678/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0345 - mae: 0.5153 - mse: 0.4449 - val_loss: 0.0177 - val_mae: 0.5373 - val_mse: 0.4864\n",
      "Epoch 679/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0355 - mae: 0.5300 - mse: 0.4721 - val_loss: 0.0176 - val_mae: 0.5348 - val_mse: 0.4715\n",
      "Epoch 680/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0362 - mae: 0.5406 - mse: 0.4838 - val_loss: 0.0177 - val_mae: 0.5354 - val_mse: 0.4825\n",
      "Epoch 681/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0352 - mae: 0.5259 - mse: 0.4660 - val_loss: 0.0169 - val_mae: 0.5135 - val_mse: 0.4419\n",
      "Epoch 682/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0344 - mae: 0.5131 - mse: 0.4403 - val_loss: 0.0171 - val_mae: 0.5195 - val_mse: 0.4415\n",
      "Epoch 683/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0351 - mae: 0.5244 - mse: 0.4502 - val_loss: 0.0174 - val_mae: 0.5267 - val_mse: 0.4651\n",
      "Epoch 684/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0349 - mae: 0.5204 - mse: 0.4533 - val_loss: 0.0171 - val_mae: 0.5170 - val_mse: 0.4464\n",
      "Epoch 685/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0345 - mae: 0.5147 - mse: 0.4423 - val_loss: 0.0172 - val_mae: 0.5225 - val_mse: 0.4447\n",
      "Epoch 686/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0354 - mae: 0.5280 - mse: 0.4545 - val_loss: 0.0174 - val_mae: 0.5285 - val_mse: 0.4691\n",
      "Epoch 687/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0350 - mae: 0.5228 - mse: 0.4583 - val_loss: 0.0169 - val_mae: 0.5113 - val_mse: 0.4365\n",
      "Epoch 688/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0341 - mae: 0.5090 - mse: 0.4350 - val_loss: 0.0170 - val_mae: 0.5164 - val_mse: 0.4416\n",
      "Epoch 689/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0347 - mae: 0.5179 - mse: 0.4483 - val_loss: 0.0180 - val_mae: 0.5464 - val_mse: 0.5014\n",
      "Epoch 690/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0359 - mae: 0.5363 - mse: 0.4852 - val_loss: 0.0173 - val_mae: 0.5244 - val_mse: 0.4489\n",
      "Epoch 691/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0355 - mae: 0.5292 - mse: 0.4611 - val_loss: 0.0171 - val_mae: 0.5179 - val_mse: 0.4501\n",
      "Epoch 692/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0345 - mae: 0.5146 - mse: 0.4438 - val_loss: 0.0172 - val_mae: 0.5198 - val_mse: 0.4533\n",
      "Epoch 693/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0345 - mae: 0.5148 - mse: 0.4459 - val_loss: 0.0171 - val_mae: 0.5178 - val_mse: 0.4386\n",
      "Epoch 694/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0348 - mae: 0.5192 - mse: 0.4426 - val_loss: 0.0170 - val_mae: 0.5151 - val_mse: 0.4455\n",
      "Epoch 695/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0343 - mae: 0.5112 - mse: 0.4385 - val_loss: 0.0170 - val_mae: 0.5145 - val_mse: 0.4462\n",
      "Epoch 696/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0343 - mae: 0.5121 - mse: 0.4413 - val_loss: 0.0170 - val_mae: 0.5162 - val_mse: 0.4428\n",
      "Epoch 697/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0346 - mae: 0.5160 - mse: 0.4463 - val_loss: 0.0174 - val_mae: 0.5265 - val_mse: 0.4682\n",
      "Epoch 698/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0348 - mae: 0.5193 - mse: 0.4572 - val_loss: 0.0170 - val_mae: 0.5138 - val_mse: 0.4389\n",
      "Epoch 699/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0345 - mae: 0.5148 - mse: 0.4436 - val_loss: 0.0170 - val_mae: 0.5149 - val_mse: 0.4461\n",
      "Epoch 700/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0342 - mae: 0.5103 - mse: 0.4378 - val_loss: 0.0169 - val_mae: 0.5109 - val_mse: 0.4358\n",
      "Epoch 701/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0341 - mae: 0.5094 - mse: 0.4335 - val_loss: 0.0168 - val_mae: 0.5106 - val_mse: 0.4330\n",
      "Epoch 702/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0342 - mae: 0.5110 - mse: 0.4330 - val_loss: 0.0170 - val_mae: 0.5139 - val_mse: 0.4429\n",
      "Epoch 703/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0341 - mae: 0.5091 - mse: 0.4362 - val_loss: 0.0168 - val_mae: 0.5098 - val_mse: 0.4331\n",
      "Epoch 704/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0340 - mae: 0.5079 - mse: 0.4316 - val_loss: 0.0169 - val_mae: 0.5108 - val_mse: 0.4373\n",
      "Epoch 705/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0340 - mae: 0.5073 - mse: 0.4340 - val_loss: 0.0169 - val_mae: 0.5129 - val_mse: 0.4424\n",
      "Epoch 706/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0341 - mae: 0.5085 - mse: 0.4364 - val_loss: 0.0169 - val_mae: 0.5115 - val_mse: 0.4370\n",
      "Epoch 707/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0341 - mae: 0.5089 - mse: 0.4370 - val_loss: 0.0170 - val_mae: 0.5159 - val_mse: 0.4485\n",
      "Epoch 708/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0341 - mae: 0.5095 - mse: 0.4388 - val_loss: 0.0169 - val_mae: 0.5121 - val_mse: 0.4342\n",
      "Epoch 709/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0344 - mae: 0.5133 - mse: 0.4381 - val_loss: 0.0171 - val_mae: 0.5196 - val_mse: 0.4544\n",
      "Epoch 710/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0344 - mae: 0.5136 - mse: 0.4462 - val_loss: 0.0169 - val_mae: 0.5116 - val_mse: 0.4324\n",
      "Epoch 711/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0342 - mae: 0.5109 - mse: 0.4340 - val_loss: 0.0169 - val_mae: 0.5121 - val_mse: 0.4394\n",
      "Epoch 712/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0341 - mae: 0.5086 - mse: 0.4350 - val_loss: 0.0169 - val_mae: 0.5117 - val_mse: 0.4395\n",
      "Epoch 713/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0340 - mae: 0.5070 - mse: 0.4340 - val_loss: 0.0169 - val_mae: 0.5110 - val_mse: 0.4338\n",
      "Epoch 714/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0342 - mae: 0.5111 - mse: 0.4367 - val_loss: 0.0172 - val_mae: 0.5208 - val_mse: 0.4584\n",
      "Epoch 715/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0345 - mae: 0.5155 - mse: 0.4490 - val_loss: 0.0171 - val_mae: 0.5169 - val_mse: 0.4416\n",
      "Epoch 716/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0346 - mae: 0.5159 - mse: 0.4448 - val_loss: 0.0173 - val_mae: 0.5241 - val_mse: 0.4638\n",
      "Epoch 717/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0346 - mae: 0.5164 - mse: 0.4519 - val_loss: 0.0169 - val_mae: 0.5115 - val_mse: 0.4323\n",
      "Epoch 718/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0342 - mae: 0.5107 - mse: 0.4344 - val_loss: 0.0168 - val_mae: 0.5099 - val_mse: 0.4346\n",
      "Epoch 719/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0340 - mae: 0.5079 - mse: 0.4310 - val_loss: 0.0170 - val_mae: 0.5148 - val_mse: 0.4459\n",
      "Epoch 720/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0341 - mae: 0.5088 - mse: 0.4373 - val_loss: 0.0169 - val_mae: 0.5131 - val_mse: 0.4345\n",
      "Epoch 721/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0344 - mae: 0.5136 - mse: 0.4374 - val_loss: 0.0171 - val_mae: 0.5167 - val_mse: 0.4506\n",
      "Epoch 722/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0344 - mae: 0.5130 - mse: 0.4453 - val_loss: 0.0168 - val_mae: 0.5094 - val_mse: 0.4342\n",
      "Epoch 723/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0339 - mae: 0.5058 - mse: 0.4299 - val_loss: 0.0168 - val_mae: 0.5096 - val_mse: 0.4336\n",
      "Epoch 724/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0340 - mae: 0.5079 - mse: 0.4350 - val_loss: 0.0171 - val_mae: 0.5186 - val_mse: 0.4535\n",
      "Epoch 725/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0344 - mae: 0.5140 - mse: 0.4446 - val_loss: 0.0170 - val_mae: 0.5147 - val_mse: 0.4361\n",
      "Epoch 726/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0344 - mae: 0.5141 - mse: 0.4387 - val_loss: 0.0172 - val_mae: 0.5207 - val_mse: 0.4567\n",
      "Epoch 727/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0345 - mae: 0.5147 - mse: 0.4486 - val_loss: 0.0168 - val_mae: 0.5100 - val_mse: 0.4305\n",
      "Epoch 728/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0340 - mae: 0.5079 - mse: 0.4299 - val_loss: 0.0168 - val_mae: 0.5087 - val_mse: 0.4310\n",
      "Epoch 729/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0340 - mae: 0.5068 - mse: 0.4294 - val_loss: 0.0171 - val_mae: 0.5174 - val_mse: 0.4518\n",
      "Epoch 730/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0343 - mae: 0.5124 - mse: 0.4443 - val_loss: 0.0171 - val_mae: 0.5190 - val_mse: 0.4446\n",
      "Epoch 731/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0348 - mae: 0.5194 - mse: 0.4489 - val_loss: 0.0179 - val_mae: 0.5437 - val_mse: 0.4984\n",
      "Epoch 732/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0359 - mae: 0.5354 - mse: 0.4849 - val_loss: 0.0175 - val_mae: 0.5292 - val_mse: 0.4533\n",
      "Epoch 733/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0357 - mae: 0.5322 - mse: 0.4618 - val_loss: 0.0170 - val_mae: 0.5166 - val_mse: 0.4477\n",
      "Epoch 734/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0342 - mae: 0.5102 - mse: 0.4388 - val_loss: 0.0173 - val_mae: 0.5253 - val_mse: 0.4640\n",
      "Epoch 735/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0347 - mae: 0.5176 - mse: 0.4525 - val_loss: 0.0172 - val_mae: 0.5210 - val_mse: 0.4407\n",
      "Epoch 736/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0350 - mae: 0.5228 - mse: 0.4469 - val_loss: 0.0169 - val_mae: 0.5108 - val_mse: 0.4374\n",
      "Epoch 737/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0340 - mae: 0.5075 - mse: 0.4325 - val_loss: 0.0172 - val_mae: 0.5225 - val_mse: 0.4606\n",
      "Epoch 738/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0345 - mae: 0.5155 - mse: 0.4493 - val_loss: 0.0176 - val_mae: 0.5325 - val_mse: 0.4677\n",
      "Epoch 739/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0359 - mae: 0.5355 - mse: 0.4765 - val_loss: 0.0182 - val_mae: 0.5511 - val_mse: 0.5096\n",
      "Epoch 740/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0364 - mae: 0.5426 - mse: 0.4957 - val_loss: 0.0170 - val_mae: 0.5140 - val_mse: 0.4343\n",
      "Epoch 741/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0344 - mae: 0.5137 - mse: 0.4338 - val_loss: 0.0174 - val_mae: 0.5265 - val_mse: 0.4458\n",
      "Epoch 742/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0356 - mae: 0.5308 - mse: 0.4551 - val_loss: 0.0175 - val_mae: 0.5290 - val_mse: 0.4691\n",
      "Epoch 743/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0349 - mae: 0.5208 - mse: 0.4564 - val_loss: 0.0171 - val_mae: 0.5173 - val_mse: 0.4485\n",
      "Epoch 744/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0342 - mae: 0.5107 - mse: 0.4383 - val_loss: 0.0176 - val_mae: 0.5335 - val_mse: 0.4638\n",
      "Epoch 745/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0359 - mae: 0.5363 - mse: 0.4726 - val_loss: 0.0181 - val_mae: 0.5485 - val_mse: 0.5055\n",
      "Epoch 746/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0360 - mae: 0.5379 - mse: 0.4882 - val_loss: 0.0168 - val_mae: 0.5100 - val_mse: 0.4330\n",
      "Epoch 747/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0339 - mae: 0.5064 - mse: 0.4294 - val_loss: 0.0172 - val_mae: 0.5216 - val_mse: 0.4445\n",
      "Epoch 748/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0350 - mae: 0.5218 - mse: 0.4492 - val_loss: 0.0177 - val_mae: 0.5363 - val_mse: 0.4832\n",
      "Epoch 749/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0354 - mae: 0.5281 - mse: 0.4694 - val_loss: 0.0170 - val_mae: 0.5142 - val_mse: 0.4414\n",
      "Epoch 750/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0343 - mae: 0.5112 - mse: 0.4363 - val_loss: 0.0173 - val_mae: 0.5257 - val_mse: 0.4469\n",
      "Epoch 751/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0356 - mae: 0.5308 - mse: 0.4565 - val_loss: 0.0171 - val_mae: 0.5177 - val_mse: 0.4495\n",
      "Epoch 752/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0344 - mae: 0.5128 - mse: 0.4429 - val_loss: 0.0172 - val_mae: 0.5204 - val_mse: 0.4553\n",
      "Epoch 753/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0345 - mae: 0.5149 - mse: 0.4465 - val_loss: 0.0174 - val_mae: 0.5284 - val_mse: 0.4575\n",
      "Epoch 754/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0357 - mae: 0.5333 - mse: 0.4685 - val_loss: 0.0173 - val_mae: 0.5242 - val_mse: 0.4624\n",
      "Epoch 755/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0347 - mae: 0.5173 - mse: 0.4516 - val_loss: 0.0169 - val_mae: 0.5128 - val_mse: 0.4407\n",
      "Epoch 756/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0340 - mae: 0.5082 - mse: 0.4348 - val_loss: 0.0172 - val_mae: 0.5211 - val_mse: 0.4413\n",
      "Epoch 757/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0350 - mae: 0.5231 - mse: 0.4466 - val_loss: 0.0171 - val_mae: 0.5177 - val_mse: 0.4500\n",
      "Epoch 758/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0342 - mae: 0.5106 - mse: 0.4382 - val_loss: 0.0170 - val_mae: 0.5165 - val_mse: 0.4485\n",
      "Epoch 759/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0341 - mae: 0.5096 - mse: 0.4377 - val_loss: 0.0172 - val_mae: 0.5221 - val_mse: 0.4460\n",
      "Epoch 760/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0352 - mae: 0.5259 - mse: 0.4549 - val_loss: 0.0174 - val_mae: 0.5264 - val_mse: 0.4671\n",
      "Epoch 761/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0348 - mae: 0.5196 - mse: 0.4558 - val_loss: 0.0168 - val_mae: 0.5085 - val_mse: 0.4325\n",
      "Epoch 762/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0339 - mae: 0.5053 - mse: 0.4302 - val_loss: 0.0170 - val_mae: 0.5149 - val_mse: 0.4359\n",
      "Epoch 763/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0346 - mae: 0.5168 - mse: 0.4410 - val_loss: 0.0172 - val_mae: 0.5226 - val_mse: 0.4602\n",
      "Epoch 764/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0346 - mae: 0.5158 - mse: 0.4508 - val_loss: 0.0168 - val_mae: 0.5078 - val_mse: 0.4304\n",
      "Epoch 765/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0338 - mae: 0.5051 - mse: 0.4261 - val_loss: 0.0169 - val_mae: 0.5115 - val_mse: 0.4318\n",
      "Epoch 766/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0343 - mae: 0.5119 - mse: 0.4348 - val_loss: 0.0173 - val_mae: 0.5246 - val_mse: 0.4636\n",
      "Epoch 767/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0346 - mae: 0.5171 - mse: 0.4517 - val_loss: 0.0168 - val_mae: 0.5091 - val_mse: 0.4294\n",
      "Epoch 768/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0341 - mae: 0.5087 - mse: 0.4307 - val_loss: 0.0168 - val_mae: 0.5080 - val_mse: 0.4292\n",
      "Epoch 769/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0339 - mae: 0.5057 - mse: 0.4279 - val_loss: 0.0172 - val_mae: 0.5213 - val_mse: 0.4581\n",
      "Epoch 770/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0344 - mae: 0.5137 - mse: 0.4470 - val_loss: 0.0170 - val_mae: 0.5150 - val_mse: 0.4369\n",
      "Epoch 771/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0344 - mae: 0.5131 - mse: 0.4378 - val_loss: 0.0169 - val_mae: 0.5113 - val_mse: 0.4392\n",
      "Epoch 772/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0340 - mae: 0.5079 - mse: 0.4336 - val_loss: 0.0168 - val_mae: 0.5103 - val_mse: 0.4369\n",
      "Epoch 773/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0338 - mae: 0.5041 - mse: 0.4289 - val_loss: 0.0168 - val_mae: 0.5105 - val_mse: 0.4310\n",
      "Epoch 774/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0342 - mae: 0.5099 - mse: 0.4314 - val_loss: 0.0169 - val_mae: 0.5117 - val_mse: 0.4407\n",
      "Epoch 775/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0341 - mae: 0.5083 - mse: 0.4349 - val_loss: 0.0168 - val_mae: 0.5082 - val_mse: 0.4328\n",
      "Epoch 776/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0337 - mae: 0.5031 - mse: 0.4274 - val_loss: 0.0168 - val_mae: 0.5089 - val_mse: 0.4317\n",
      "Epoch 777/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0339 - mae: 0.5059 - mse: 0.4324 - val_loss: 0.0170 - val_mae: 0.5146 - val_mse: 0.4467\n",
      "Epoch 778/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0340 - mae: 0.5075 - mse: 0.4370 - val_loss: 0.0169 - val_mae: 0.5109 - val_mse: 0.4317\n",
      "Epoch 779/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0342 - mae: 0.5103 - mse: 0.4345 - val_loss: 0.0170 - val_mae: 0.5137 - val_mse: 0.4443\n",
      "Epoch 780/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0341 - mae: 0.5090 - mse: 0.4378 - val_loss: 0.0167 - val_mae: 0.5074 - val_mse: 0.4274\n",
      "Epoch 781/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0337 - mae: 0.5036 - mse: 0.4241 - val_loss: 0.0167 - val_mae: 0.5068 - val_mse: 0.4283\n",
      "Epoch 782/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0337 - mae: 0.5037 - mse: 0.4260 - val_loss: 0.0169 - val_mae: 0.5113 - val_mse: 0.4407\n",
      "Epoch 783/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0338 - mae: 0.5051 - mse: 0.4324 - val_loss: 0.0169 - val_mae: 0.5107 - val_mse: 0.4329\n",
      "Epoch 784/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0342 - mae: 0.5106 - mse: 0.4364 - val_loss: 0.0171 - val_mae: 0.5168 - val_mse: 0.4513\n",
      "Epoch 785/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0342 - mae: 0.5104 - mse: 0.4417 - val_loss: 0.0168 - val_mae: 0.5094 - val_mse: 0.4291\n",
      "Epoch 786/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0341 - mae: 0.5088 - mse: 0.4305 - val_loss: 0.0168 - val_mae: 0.5079 - val_mse: 0.4323\n",
      "Epoch 787/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0338 - mae: 0.5043 - mse: 0.4270 - val_loss: 0.0168 - val_mae: 0.5096 - val_mse: 0.4363\n",
      "Epoch 788/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0337 - mae: 0.5036 - mse: 0.4294 - val_loss: 0.0168 - val_mae: 0.5099 - val_mse: 0.4297\n",
      "Epoch 789/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0340 - mae: 0.5078 - mse: 0.4283 - val_loss: 0.0169 - val_mae: 0.5134 - val_mse: 0.4452\n",
      "Epoch 790/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0340 - mae: 0.5081 - mse: 0.4380 - val_loss: 0.0167 - val_mae: 0.5075 - val_mse: 0.4302\n",
      "Epoch 791/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0339 - mae: 0.5063 - mse: 0.4319 - val_loss: 0.0167 - val_mae: 0.5067 - val_mse: 0.4306\n",
      "Epoch 792/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0337 - mae: 0.5026 - mse: 0.4264 - val_loss: 0.0168 - val_mae: 0.5086 - val_mse: 0.4352\n",
      "Epoch 793/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0337 - mae: 0.5030 - mse: 0.4272 - val_loss: 0.0168 - val_mae: 0.5079 - val_mse: 0.4274\n",
      "Epoch 794/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0339 - mae: 0.5055 - mse: 0.4270 - val_loss: 0.0169 - val_mae: 0.5108 - val_mse: 0.4391\n",
      "Epoch 795/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0339 - mae: 0.5055 - mse: 0.4322 - val_loss: 0.0167 - val_mae: 0.5068 - val_mse: 0.4265\n",
      "Epoch 796/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0337 - mae: 0.5034 - mse: 0.4241 - val_loss: 0.0167 - val_mae: 0.5073 - val_mse: 0.4328\n",
      "Epoch 797/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0337 - mae: 0.5024 - mse: 0.4256 - val_loss: 0.0167 - val_mae: 0.5057 - val_mse: 0.4281\n",
      "Epoch 798/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0336 - mae: 0.5020 - mse: 0.4239 - val_loss: 0.0167 - val_mae: 0.5057 - val_mse: 0.4282\n",
      "Epoch 799/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0335 - mae: 0.5003 - mse: 0.4226 - val_loss: 0.0167 - val_mae: 0.5070 - val_mse: 0.4334\n",
      "Epoch 800/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0337 - mae: 0.5025 - mse: 0.4276 - val_loss: 0.0167 - val_mae: 0.5072 - val_mse: 0.4274\n",
      "Epoch 801/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0337 - mae: 0.5031 - mse: 0.4254 - val_loss: 0.0169 - val_mae: 0.5126 - val_mse: 0.4442\n",
      "Epoch 802/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0340 - mae: 0.5068 - mse: 0.4376 - val_loss: 0.0169 - val_mae: 0.5115 - val_mse: 0.4303\n",
      "Epoch 803/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0342 - mae: 0.5105 - mse: 0.4328 - val_loss: 0.0170 - val_mae: 0.5164 - val_mse: 0.4507\n",
      "Epoch 804/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0342 - mae: 0.5101 - mse: 0.4409 - val_loss: 0.0168 - val_mae: 0.5083 - val_mse: 0.4269\n",
      "Epoch 805/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0339 - mae: 0.5065 - mse: 0.4265 - val_loss: 0.0167 - val_mae: 0.5067 - val_mse: 0.4320\n",
      "Epoch 806/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0336 - mae: 0.5011 - mse: 0.4253 - val_loss: 0.0167 - val_mae: 0.5056 - val_mse: 0.4293\n",
      "Epoch 807/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0335 - mae: 0.5005 - mse: 0.4261 - val_loss: 0.0167 - val_mae: 0.5057 - val_mse: 0.4283\n",
      "Epoch 808/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0336 - mae: 0.5009 - mse: 0.4234 - val_loss: 0.0168 - val_mae: 0.5079 - val_mse: 0.4349\n",
      "Epoch 809/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0337 - mae: 0.5033 - mse: 0.4285 - val_loss: 0.0167 - val_mae: 0.5066 - val_mse: 0.4259\n",
      "Epoch 810/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0337 - mae: 0.5030 - mse: 0.4235 - val_loss: 0.0168 - val_mae: 0.5081 - val_mse: 0.4335\n",
      "Epoch 811/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0338 - mae: 0.5050 - mse: 0.4302 - val_loss: 0.0167 - val_mae: 0.5050 - val_mse: 0.4255\n",
      "Epoch 812/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0337 - mae: 0.5025 - mse: 0.4236 - val_loss: 0.0167 - val_mae: 0.5048 - val_mse: 0.4265\n",
      "Epoch 813/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0336 - mae: 0.5016 - mse: 0.4236 - val_loss: 0.0167 - val_mae: 0.5071 - val_mse: 0.4344\n",
      "Epoch 814/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0338 - mae: 0.5038 - mse: 0.4304 - val_loss: 0.0168 - val_mae: 0.5102 - val_mse: 0.4327\n",
      "Epoch 815/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0340 - mae: 0.5076 - mse: 0.4332 - val_loss: 0.0173 - val_mae: 0.5253 - val_mse: 0.4680\n",
      "Epoch 816/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0347 - mae: 0.5186 - mse: 0.4579 - val_loss: 0.0175 - val_mae: 0.5295 - val_mse: 0.4518\n",
      "Epoch 817/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0357 - mae: 0.5321 - mse: 0.4602 - val_loss: 0.0173 - val_mae: 0.5245 - val_mse: 0.4647\n",
      "Epoch 818/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0347 - mae: 0.5178 - mse: 0.4568 - val_loss: 0.0168 - val_mae: 0.5091 - val_mse: 0.4320\n",
      "Epoch 819/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0338 - mae: 0.5047 - mse: 0.4266 - val_loss: 0.0171 - val_mae: 0.5175 - val_mse: 0.4366\n",
      "Epoch 820/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0347 - mae: 0.5177 - mse: 0.4398 - val_loss: 0.0173 - val_mae: 0.5233 - val_mse: 0.4629\n",
      "Epoch 821/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0347 - mae: 0.5178 - mse: 0.4529 - val_loss: 0.0168 - val_mae: 0.5097 - val_mse: 0.4337\n",
      "Epoch 822/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0339 - mae: 0.5057 - mse: 0.4299 - val_loss: 0.0167 - val_mae: 0.5063 - val_mse: 0.4280\n",
      "Epoch 823/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0336 - mae: 0.5021 - mse: 0.4238 - val_loss: 0.0170 - val_mae: 0.5141 - val_mse: 0.4443\n",
      "Epoch 824/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0340 - mae: 0.5072 - mse: 0.4359 - val_loss: 0.0168 - val_mae: 0.5088 - val_mse: 0.4263\n",
      "Epoch 825/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0340 - mae: 0.5069 - mse: 0.4258 - val_loss: 0.0167 - val_mae: 0.5061 - val_mse: 0.4267\n",
      "Epoch 826/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0336 - mae: 0.5020 - mse: 0.4219 - val_loss: 0.0169 - val_mae: 0.5125 - val_mse: 0.4428\n",
      "Epoch 827/2000\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.0339 - mae: 0.5065 - mse: 0.4344 - val_loss: 0.0171 - val_mae: 0.5193 - val_mse: 0.4451\n",
      "Epoch 828/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0347 - mae: 0.5178 - mse: 0.4465 - val_loss: 0.0180 - val_mae: 0.5449 - val_mse: 0.5013\n",
      "Epoch 829/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0360 - mae: 0.5373 - mse: 0.4890 - val_loss: 0.0175 - val_mae: 0.5292 - val_mse: 0.4501\n",
      "Epoch 830/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0354 - mae: 0.5291 - mse: 0.4532 - val_loss: 0.0168 - val_mae: 0.5101 - val_mse: 0.4320\n",
      "Epoch 831/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0339 - mae: 0.5059 - mse: 0.4269 - val_loss: 0.0176 - val_mae: 0.5334 - val_mse: 0.4790\n",
      "Epoch 832/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0352 - mae: 0.5257 - mse: 0.4675 - val_loss: 0.0170 - val_mae: 0.5142 - val_mse: 0.4337\n",
      "Epoch 833/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0344 - mae: 0.5139 - mse: 0.4365 - val_loss: 0.0167 - val_mae: 0.5075 - val_mse: 0.4288\n",
      "Epoch 834/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0338 - mae: 0.5039 - mse: 0.4250 - val_loss: 0.0173 - val_mae: 0.5257 - val_mse: 0.4657\n",
      "Epoch 835/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0348 - mae: 0.5193 - mse: 0.4546 - val_loss: 0.0170 - val_mae: 0.5152 - val_mse: 0.4365\n",
      "Epoch 836/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0345 - mae: 0.5143 - mse: 0.4396 - val_loss: 0.0167 - val_mae: 0.5071 - val_mse: 0.4286\n",
      "Epoch 837/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0337 - mae: 0.5031 - mse: 0.4235 - val_loss: 0.0171 - val_mae: 0.5172 - val_mse: 0.4492\n",
      "Epoch 838/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0343 - mae: 0.5117 - mse: 0.4406 - val_loss: 0.0168 - val_mae: 0.5096 - val_mse: 0.4268\n",
      "Epoch 839/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0339 - mae: 0.5064 - mse: 0.4241 - val_loss: 0.0167 - val_mae: 0.5052 - val_mse: 0.4255\n",
      "Epoch 840/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0335 - mae: 0.5007 - mse: 0.4208 - val_loss: 0.0170 - val_mae: 0.5164 - val_mse: 0.4510\n",
      "Epoch 841/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0342 - mae: 0.5106 - mse: 0.4417 - val_loss: 0.0173 - val_mae: 0.5233 - val_mse: 0.4513\n",
      "Epoch 842/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0350 - mae: 0.5231 - mse: 0.4553 - val_loss: 0.0179 - val_mae: 0.5411 - val_mse: 0.4944\n",
      "Epoch 843/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0358 - mae: 0.5336 - mse: 0.4824 - val_loss: 0.0171 - val_mae: 0.5181 - val_mse: 0.4354\n",
      "Epoch 844/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0346 - mae: 0.5167 - mse: 0.4371 - val_loss: 0.0170 - val_mae: 0.5154 - val_mse: 0.4334\n",
      "Epoch 845/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0345 - mae: 0.5147 - mse: 0.4343 - val_loss: 0.0176 - val_mae: 0.5337 - val_mse: 0.4802\n",
      "Epoch 846/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0353 - mae: 0.5263 - mse: 0.4680 - val_loss: 0.0168 - val_mae: 0.5091 - val_mse: 0.4309\n",
      "Epoch 847/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0339 - mae: 0.5056 - mse: 0.4292 - val_loss: 0.0169 - val_mae: 0.5126 - val_mse: 0.4371\n",
      "Epoch 848/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0341 - mae: 0.5088 - mse: 0.4362 - val_loss: 0.0177 - val_mae: 0.5376 - val_mse: 0.4863\n",
      "Epoch 849/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0355 - mae: 0.5302 - mse: 0.4735 - val_loss: 0.0169 - val_mae: 0.5115 - val_mse: 0.4287\n",
      "Epoch 850/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0341 - mae: 0.5092 - mse: 0.4275 - val_loss: 0.0169 - val_mae: 0.5121 - val_mse: 0.4285\n",
      "Epoch 851/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0341 - mae: 0.5094 - mse: 0.4252 - val_loss: 0.0173 - val_mae: 0.5251 - val_mse: 0.4624\n",
      "Epoch 852/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0347 - mae: 0.5179 - mse: 0.4521 - val_loss: 0.0168 - val_mae: 0.5078 - val_mse: 0.4303\n",
      "Epoch 853/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0336 - mae: 0.5021 - mse: 0.4233 - val_loss: 0.0173 - val_mae: 0.5235 - val_mse: 0.4497\n",
      "Epoch 854/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0352 - mae: 0.5250 - mse: 0.4547 - val_loss: 0.0179 - val_mae: 0.5431 - val_mse: 0.4955\n",
      "Epoch 855/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0358 - mae: 0.5342 - mse: 0.4826 - val_loss: 0.0167 - val_mae: 0.5069 - val_mse: 0.4259\n",
      "Epoch 856/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0338 - mae: 0.5042 - mse: 0.4233 - val_loss: 0.0172 - val_mae: 0.5203 - val_mse: 0.4390\n",
      "Epoch 857/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0348 - mae: 0.5200 - mse: 0.4420 - val_loss: 0.0172 - val_mae: 0.5219 - val_mse: 0.4576\n",
      "Epoch 858/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0345 - mae: 0.5151 - mse: 0.4477 - val_loss: 0.0169 - val_mae: 0.5123 - val_mse: 0.4403\n",
      "Epoch 859/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0340 - mae: 0.5080 - mse: 0.4339 - val_loss: 0.0173 - val_mae: 0.5248 - val_mse: 0.4489\n",
      "Epoch 860/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0352 - mae: 0.5253 - mse: 0.4553 - val_loss: 0.0170 - val_mae: 0.5141 - val_mse: 0.4436\n",
      "Epoch 861/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.0340 - mae: 0.5077 - mse: 0.4351 - val_loss: 0.0170 - val_mae: 0.5145 - val_mse: 0.4441\n",
      "Epoch 862/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.0339 - mae: 0.5066 - mse: 0.4333 - val_loss: 0.0171 - val_mae: 0.5169 - val_mse: 0.4346\n"
     ]
    }
   ],
   "source": [
    "gcn.fit(train_mask, valid_mask, n_epochs = 2000) #fit model on train data (train mask) by using validation data (valid_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j8BmgrBqz5yY"
   },
   "outputs": [],
   "source": [
    "y_pred = gcn.predict(valid_mask) #predict on test or validation data\n",
    "print(mae(np.expm1(y[valid_mask]), np.round(np.expm1(y_pred))))#validation mae score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lcktgr2LV2BG"
   },
   "source": [
    "# Doc2Vec + Deep_Walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ceioRLDebEe",
    "outputId": "57c9ee95-7421-46e2-c373-23e75702c74c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24767599269232463\n",
      "0.5440698584320326\n"
     ]
    }
   ],
   "source": [
    "df_train_0, df_auth_emb_Doc2vec_1 = remove_embedding(df_train, df_auth_emb_Doc2vec)\n",
    "df_node_emb_pca = pca_node_embedding(20, df_node_emb)\n",
    "auth_doc2vec_pca  = pca_author_embedding(100, df_auth_emb_Doc2vec_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fHtf-OtyvYPX",
    "outputId": "6ad706ad-212a-486c-e35b-72546d03cd40"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22872it [01:12, 315.07it/s]\n"
     ]
    }
   ],
   "source": [
    "dim_0 = df_train_0.shape[0]\n",
    "f_n = features_df.shape[1]\n",
    "Doc2vec_n = auth_doc2vec_pca.shape[1]\n",
    "nod_em_n = df_node_emb_pca.shape[1]\n",
    "X_train = np.zeros((dim_0,f_n+4+nod_em_n+Doc2vec_n))\n",
    "y_train = np.zeros(dim_0)\n",
    "X_train, y_train = generate_data(X_train, y_train, df_train_0, features_df,  all_data=False, doc2vec = True, Bert = False)\n",
    "X_t, X_v, y_t, y_v = train_test_split(X_train, y_train, test_size=0.33, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ju8pySjKssyb",
    "outputId": "48e7f1a6-f886-4a31-b54c-410090ead2a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Performing LGBMRegressor---\n",
      "mae for lighgbm :  3.325781664016958\n"
     ]
    }
   ],
   "source": [
    "lgb_reg, _ , _ = base_models()\n",
    "X_t, X_v, y_t, y_v = train_test_split(X_train, y_train, test_size=0.33, random_state=7)\n",
    "print('mae for lighgbm : ', error(lgb_reg, X_t, X_v, y_t, y_v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7aAIKTVEc0Nk"
   },
   "source": [
    "# Bert + Deep_Walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ynFHRamyWseA",
    "outputId": "79b609b8-1fd4-4c19-eaec-9dd703d9071d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24767599269232485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23124it [01:18, 296.02it/s]\n"
     ]
    }
   ],
   "source": [
    "dim_0 = df_train.shape[0]\n",
    "df_node_emb_pca = pca_node_embedding(20, df_node_emb)\n",
    "nod_em_n = df_node_emb_pca.shape[1]\n",
    "X_train = np.zeros((dim_0,f_n+4+nod_em_n+Bert_n))\n",
    "y_train = np.zeros(dim_0)\n",
    "X_train, y_train = generate_data(X_train, y_train, df_train, features_df,  all_data=False, doc2vec = False, Bert = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n1dox6SPOnA-",
    "outputId": "10091f1c-157b-4aea-f718-e5789fb007d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Performing LGBMRegressor---\n",
      "mae for lighgbm :  3.1643297077709343\n"
     ]
    }
   ],
   "source": [
    "lgb_reg, _ , _ = base_models()\n",
    "X_t, X_v, y_t, y_v = train_test_split(X_train, y_train, test_size=0.33, random_state=7)\n",
    "print('mae for lighgbm : ', error(lgb_reg, X_t, X_v, y_t, y_v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtep8zpVcfGR"
   },
   "source": [
    "# Doc2vec + Bert + Deep_Walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yNXZKTFXus_W",
    "outputId": "c1f34f24-b91d-4bc8-a976-691c9675c393"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28119939295253166\n",
      "0.4123955915736107\n"
     ]
    }
   ],
   "source": [
    "df_node_emb_pca = pca_node_embedding(25, df_node_emb)\n",
    "auth_doc2vec_pca  = pca_author_embedding(64, df_auth_emb_Doc2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wuU1PAB1i34t",
    "outputId": "70d64a2a-d081-42b9-feb0-d4237628a83c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23124it [01:55, 200.07it/s]\n"
     ]
    }
   ],
   "source": [
    "dim_0 = df_train.shape[0]\n",
    "f_n = features_df.shape[1]\n",
    "Doc2vec_n = auth_doc2vec_pca.shape[1]\n",
    "nod_em_n = df_node_emb_pca.shape[1]\n",
    "Bert_n = df_auth_emb_Bert.shape[1]\n",
    "X_train = np.zeros((dim_0,f_n+4+nod_em_n+Bert_n+Doc2vec_n))\n",
    "y_train = np.zeros(dim_0)\n",
    "X_train, y_train = generate_data(X_train, y_train, df_train, features_df,  all_data=False, doc2vec = True, Bert = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXXwbDmjy5mz"
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cs-WSlLAy9iD"
   },
   "outputs": [],
   "source": [
    "lgb_reg, cat_reg, xg_reg = base_models()\n",
    "X_t, X_v, y_t, y_v = train_test_split(X_train, y_train, test_size=0.33, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "79RuquGnuoRu",
    "outputId": "7ef8f4ae-b038-458c-95ec-28e335b2152e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Performing CatBoostRegressor---\n",
      "mae for catboost :  3.279124623247281\n",
      "---Performing LGBMRegressor---\n",
      "mae for lighgbm :  3.1163674485650636\n",
      "---Performing XGBRegressor---\n",
      "mae for xgboost :  3.2552745380684054\n"
     ]
    }
   ],
   "source": [
    "print('mae for catboost : ', error(cat_reg, X_t, X_v, y_t, y_v))\n",
    "print('mae for lighgbm : ', error(lgb_reg, X_t, X_v, y_t, y_v))\n",
    "print('mae for xgboost : ', error(xg_reg, X_t, X_v, y_t, y_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0TW_bgpF5nJ"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "lgb_reg, cat_reg, xg_reg = base_models()\n",
    "Averaging_models = AveragingModels(X_t, y_t, [lgb_reg, cat_reg, xg_reg])\n",
    "Averaging_models.fit(X_t, y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oaDn1AJibeNy",
    "outputId": "5691c8c2-eac1-424c-ae35-40f0a48b4ee6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae for Averaging_models :  3.1611846415935\n"
     ]
    }
   ],
   "source": [
    "error_avg = mae(np.expm1(y_v), np.round(np.expm1(Averaging_models.predict(X_v))))\n",
    "print('mae for Averaging_models : ', error_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3TAa9nvNpGMY"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "regressor = Stacking_regressor(lgb_reg, cat_reg, xg_reg)\n",
    "regressor.fit(X_t, y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b2nomj82CsCy",
    "outputId": "807dedef-cd22-4368-b8ba-c3956ff6c51a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae for Stacking_regressor :  3.114401782204167\n"
     ]
    }
   ],
   "source": [
    "error_stacking = mae(np.expm1(y_v), np.round(np.expm1(regressor.predict(X_v))))\n",
    "print('mae for Stacking_regressor : ', error_stacking)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Altegrad Models.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
